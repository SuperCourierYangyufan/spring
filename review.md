# 一期

### jvm
1. java代码编译器产生.Class文件(字节码文件)(如jdk命令),字节码文件通过jvm的解释器在不同的平台产生不同的机器码
2. 线程私有数据区域与线程生命周期相同,会根据线程的创建而创建，销毁而销毁;线程共享区则会随虚拟机的创建而创建，销毁而销毁
3. Jvm构成
    1. 程序计数器     |私有| 显示当前线程所执行的字节码的行号
    2. 虚拟机栈       |私有| 为一个栈,用于存储 局部变量，操作数栈，动态链接，方法出口信息
    3. 本地方法区     |私有| 执行native方法服务
    4. 堆             |共享| 创建的对象和数组保存在此
    5. 方法区(永久代) |共享| 被jvm加载的信息,如常量,静态变量,即使编译的代码(字节码),运行时常量池也是其中一部分,用于存放编译生成  
        的各种字面量和符号引用
4. 堆从GC角度分为 新生代 老年代
    1. 新生代:老年代 1:2
    2. 新生代分为 Eden:ServivorFrom:ServivorTo 8:1:1
    3. 新生代采用 复制清除算法  老年代采用 标记整理算法    
5. 永久代指内存永久保存区域,主要存放Class和元数据信息,JDK8永久代移除,替代有一个元空间，本质上区别元空间不在虚拟机中而是  
    使用直接内存
6. 确定垃圾采用可达性分析,Gc Root包含虚拟机栈中引用的对象,方法区类静态属性引用的对象，方法区常量池引用的对象，本地方法栈 JNI 引用的对象
7. 垃圾回收算法
    1. 标记清除算法
    2. 复制清除算法    
    3. 标记整理算法
    4. 分代收集算法
8. JAVA 四中引用类型
    1. 强 它是不可能被垃圾回收机制回收的
    2. 软 当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收
    3. 弱 只要垃圾回收机制一运行，不管JVM的内存空间是否足够，总会回收该对象占用的内存
    4. 虚 虚引用的主要作用是跟踪对象被垃圾回收的状态
9. 垃圾收集器
    1. Serial(C rv o)             新/老  单线程  复制算法/标记整理
    2. ParNew             新     多线程  复制算法
    3. Parallel Scavenge(par en 冷 斯嘎润几)  新/老  多线程  复制算法/标记整理 它重点关注的是程序达到一个可控制的吞吐量，自适应调节策略也是  
    ParallelScavenge收集器与ParNew收集器的一个重要区别
    4. CMS                老     多线程  标记整理          主要目标是获取最短垃圾回收停顿时间,还是有垃圾碎片的问题,流程如下
        1. 标记GC Roots能直接关联的对象,仍然需要暂停所有的工作线程
        2. 进行GC Roots跟踪的过程，和用户线程一起工作，不需要暂停工作线程
        3. 修正跟踪期间变化的标记，仍然需要暂停所有的工作线程
        4. 清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程
    5. G1  
        1. 基于标记-整理算法，不产生内存碎片
        2. 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收
        3. G1收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，优先回收垃圾最多的区域
        4. 宏观上不区分新老区,微观分为Eden,survivor,Old,Humongous(大对象)
        5. 在堆的使用上,G1不要求对象的存储一定要物理连续,逻辑连续便可,也不是固定为某个代服务
        6. GC时,年轻代依旧暂停所有线程,将活的对象拷贝到survivor,多个survivor,old可以合并,[并且形成连续的内存块]
        7. 搜集过程和CMS一致
    6. 使用
        - 单cpu或者小内存 用-XX:+UseSerialGC
        - 多CPU,需要最大吞吐,如后台计算 -XX:+UseParallelGc
        - 最求低停顿,需要快速响应 -XX:+UseConcMarkSweepGc
10. new 一个对象过程 
    * java在new一个对象的时候，会先查看对象所属的类有没有被加载到内存，如果没有的话，就会先通过类的全限定名来加载。  
    加载并初始化类完成后，再进行对象的创建工作
    * 类加载过程（第一次使用该类）
        1. 加载    由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，  
        然后将其转换为一个与目标类型对应的java.lang.Class对象实例
        2. 验证   确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求
            - 文件格式验证：验证字节流是否符合 Class 文件的规范，如主次版本号是否在当前虚拟机范围内，常量池中的常量是否有不被  
            支持的类型
            - 元数据验证:对字节码描述的信息进行语义分析，如这个类是否有父类，是否集成了不被继承的类等
            - 字节码验证：是整个验证过程中最复杂的一个阶段，通过验证数据流和控制流的分析，确定程序语义是否正确，主要针对方法体的  
            验证。如：方法中的类型转换是否正确，跳转指令是否正确等
            - 符号引用验证：这个动作在后面的解析过程中发生，主要是为了确保解析动作能正确执行。
        3. 准备   为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内）  
                被final修饰的static变量（常量），会直接赋值
        4. 解析   虚拟机将常量池中的符号引用(字节码的标识 如 CONSTANT_Field_info3)替换为直接引用(地址指向)的过程
        5. 初始化 初始化阶段是执行类构造器<client>方法的过程,如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以  
        不为这个类生成<client>()方法
    * 创建对象
        1. 在堆区分配对象需要的内存，分配的内存包括本类和父类的所有实例变量，但不包括任何静态变量
        2. 对所有实例变量赋默认值,将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值
        3. 执行实例初始化代码,初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法
        4. 如果有类似于Child c = new Child()形式的c引用的话，在栈区定义Child类型引用变量c，然后将堆区对象的地址赋值给它      
11. 类加载器 
    1. 自定义加载器->应用程序类加载器->扩展类加载器->启动类加载器
    2. 当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成,父类不行才交付子类
    3. 好处是不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得  
    到的都是同样一个Object对象。
    4. 怎么打破双亲委派模型?打破双亲委派机制则不仅要继承ClassLoader类，还要重写loadClass和findClass方法
12. SafePoint
    * 比如 GC 的时候必须要等到 Java 线程都进入到 safepoint 的时候 VMThread 才能开始执行 GC
    * 比如
        - 循环的末尾 (防止大循环的时候一直不进入 safepoint，而其他线程在等待它进入safepoint)
        - 方法返回前
        - 调用方法的 call 之后
        - 抛出异常的位置
13. 内存泄漏和内存溢出
    * 内存泄漏:是指程序中动态分配的堆内存由于某种原因未释放或者无法释放，造成的程序运行速度变慢和崩溃等后果。
        - 非静态内部类默示持有外部类的引用
        - 单例模式会造成内存泄漏
        - 非静态内部类
        - 外部类持有非静态内部类的静态对象
        - Handler 或 Runnable 作为非静态内部类
        - BraodcastReceiver 未取消注册，InputStream 未关闭等
    * 内存溢出:通俗理解就是内存不够，是指系统中存在中无法回收的内存或者使用的内存过多，最终使程序运行大于能提供的最大内存。
        - 内存中加载的数据过于庞大，如一次从数据库中取出多个数据
        - 集合类中有对象的引用，使用后未对其进行清空，使JVM无法回收
        - 代码中存在死循环或循环产生过多重复的对象实体
        - 内存设置过小
14. JVM系统参数
    1. jps -l ->查看正在运行的java进程
    2. jinfo -flag 属性值 进程编号 ->查看某个属性是否被激活/jinfo -flags 进程编号
    3. -XX: +PrintGCDetails 开启GC日志(+开启,-关闭)
    4. -XX: MetaspaceSize=128m 设置元空间值
    5. -XX: MaxTenuringThreshold=15 控制新生代需要经历多少次GC晋升到老年代中的最大阈值
    6. -Xms == -XX: initialHeapSize 初始化堆内存
    7. -Xmx == -XX: MaxHeapSize 最大堆内存 
    8. java -XX: +PrintFlagInitial jvm初始化参数
    9. java -XX: +PrintFlagsFinal 修改以后的参数
    10. java -XX: +PrintCommandLineFlags -version 查看常用参数+垃圾回收器
    11. -Xmn 年轻代,-Xss 每个线程堆栈大小
    12. 使用Arthas（阿尔萨斯）
15. GC详解(-XX: +PrintGCDetail)
    *  Gc 新生区 ,Full GC 养老区
    *  [GC[PSyoungGen:334480k->4736k(334848K)]597914K->270331K(1017536K),0.0209890 secs][Times:user=0.03 sys=0.00,real=0.02 secs] 
    *  [[GC类型:youngGc前新生代内存->youngGc后新生代内存(新生代总大小)]GC前堆大小->GC后堆大小(JVM堆总大小),GC耗时[用户/系统/实际(GC耗时)]     
    
### 集合
1.  List
    1. ArrayList
        - 使用无参构造方法,ArrayList对象中的数组初始长度为0
        - 当第一次add默认扩容为10
        - 扩容背数:(旧大小*3/2)+1,因子1.5
        - 先确定是否需要扩容,再插入值
        - 非线程安全，多线程环境下必须在外部增加同步限制，或者使用包装对象 List list = Collections.synchronizedList(new ArrayList(...))
        - 删除元素就是把元素后每一位都往前挪，时间复杂度为 O(n)
        - 默认数组和快速失败次数两个元素采用transient关键字修饰,该关键字可让被修饰的成员属性变量不被序列化,原因是100大小的数组,只用了50个,默认  
        会全部序列化。
        - 快速失败(modCount)用来记录 ArrayList 结构发生变化的次数，如果一个动作前后 modCount 的值不相等，说明 ArrayList 被其它线程修改了,主要是为了在使用迭代器时修改数组  
    2. LinkedList    
        - 双向链表
        - add()本质上是linkLast(),向链表最后添加一条数据
        - 可以作为一个队列使用(双向队列也可以),栈
        - 循环建议迭代器,get()方法,从头或尾部循环过来,迭代器一直指向下一个节点
    3. CopyOnWriteArrayList
        - 他的设计思想是:读写分离,最终一致,写时复制
        - 它不能指定容量,初始容量是0.它底层也是一个数组,集合有多大,底层数组就有多大,不会有多余的空间
        - 缺点底层是数组,删除插入的效率不高,写的时候需要复制,占用内存,浪费空间,如果集合足够大的时候容易触发GC
        - 和vector相比,读大于写 用CopyOnWriteArrayList,写比较多Vector(歪克特)
        
2. Set
    1. HashSet,TreeSet(自己定义的类必须实现Comparable接口，并且覆写相应的compareTo()函数),LinkHashSet(基于LinkHashMap)
3. Map
    1. HashMap 数组+链表+红黑树
        1. 只允许一条记录key=null,允许多条value=null
        2. 扩容=2,负载=0.75,初始容量默认16(Hashtable初始容量为11,扩容为 *2+1)
        3. 7->8 从链表长度8个以后为红黑树 时间复杂度从O(n)->O(logN)
        4. HashMap为何线程不安全
            - put时key相同导致其中⼀个线程的value被覆盖
            - 多个线程同时扩容，造成数据丢失
            - 多线程扩容时导致Node链表形成环形结构造成.next()死循环，导致CPU利⽤率接近100%
        5. HashMap在初始化阶段不会马上创建哈希表
        6. 红黑树
            - 时间复杂度为O(logn)
            - 红黑树是一种近似平衡的二叉查找树，其主要的优点就是平衡，即左右子树高度几乎一致，以此来防止树退化为链表
            - 每个节点要么是黑色，要么是红色，但根节点必须是黑色的
            - 每个红色节点的两个子节点必须是黑色的
            - 红色节点不能连续（即红色节点的孩子和父亲都不能是红色的）
            - 从任意节点到其子树中每个叶子结点的路径都包含相同数量的黑色节点
            - 所有的叶子节点都是黑色的
            - 新加入到红黑树的节点为红色节点
            - mysql不用红黑树的原因是数据多的时候太高了
        7. 新元素插入数组节点下列表时,7前采用头插法,8后采用尾插法
            - 当采用头插法时,同时两个线程A,B进来,链表为(头)A->B(尾),然后扩容,先插入A,找到下一个节点B插入,新的链表为B->A,  
            但是之前链表为A->B,一直找下一个会照成死循环,8采用红黑树,尾插法就没有这个问题
        8. 为什么默认初始值为16?为什么初始化需要为2的幂
            - 这样是为了位运算的方便，位与运算比算数计算的效率高了很多，之所以选择16,因为是计算hash值为(hashCode & (16-1))  
            而16-1=15,15二进制就是1111,这样hashcode进行比较时,只需要看后几位。这样就将位运算代替了取模。
    2. ConcurrentHashMap 分段锁,默认分段数为16,JDK8同样引入红黑树
    3. HashTable 
    4. TreeMap 实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序。key必须实现Comparable接口或者在  
    构造TreeMap传入自定义的Comparator
    5. LinkHashMap 

### 线程
1. 线程实现方法
    1. 继承Thread类,重写run()方法,类.start()启动线程,start()为native方法
    2. 实现Runnable接口，实现run()方法,new Thread(实现类).start()
    3. 实现Callable接口.可以得到有结果返回的Future对象
2. 线程池 Executor(一栽Q特)
    1. public ThreadPoolExecutor(int corePoolSize, // 核心线程池大小  
                                 int maximumPoolSize,  // 最大线程池大小  
                                 long keepAliveTime,  // 线程最大空闲时间  
                                 TimeUnit unit,  // 时间单位  
                                 BlockingQueue<Runnable> workQueue, // 用于存放提交的任务，队列的实际容量与线程池大小相关联  
                                 ThreadFactory threadFactory,  // 线程工厂，用于创建线程，一般用默认即可    
                                 RejectedExecutionHandler handler )  //当任务太多来不及处理时，如何拒绝任务   
    2. 线程等待队列
        1. 阻塞队列
            1. LinkedBlockingQueue<Runnable>() 可用于Web服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞，由链表结构  
            组成的无界阻塞队列,先进先出排序,特定是对消费端和生成端分别采用独立锁,锁细分
            2. SynchronousQueue<Runnable>() 快速处理大量耗时较短的任务，如Netty的NIO接受请求时 并发同步阻塞不存储元素队列,
            每一个put操作必须等待一个take操作，否则不能继续添加元素
            3. ArrayBlockingQueue 由数组结构组成的有界阻塞队列,先进先出排序,默认情况不保证访问者的公平性
            4. PriorityBlockingQueue  支持优先级排序的无界阻塞队列,默认采用元素自然顺序排序,或自定义CompareTo()排序
            5. DelayQueue 使用优先级队列实现的无界阻塞队列,特点是支持延时和获取元素,底层使用PriorityQueue来实现,可用于定时
            任务或缓存的使用
            6. LinkedTransferQueue 由链表结构组成的无界阻塞队列
            7. LinkedBlockingDeque 由链表结构组成的双向阻塞队列
        2. 若任务数量>核心线程池数量,且无空闲任务线程,且>max线程数,则任务将会被拒绝
        3. 队列策略
            1. 直接握手队列它将任务交给线程而不需要保留。这里，如果没有线程立即可用来运行它，那么排队任务的尝试将失败，因  
            此将构建新的线程。
            2. 无界队列当所有corePoolSize线程繁忙时，使用无界队列将导致新任务在队列中等待，从而导致maximumPoolSize的值没  
            有任何作用
            3. 有界队列一个有界的队列和有限的maximumPoolSizes配置有助于防止资源耗尽，但是难以控制。队列大小和maximumPoolSizes  
            需要 相互权衡
            4. 有界和无界最大区别就是队列数量有无界限
        4.  如果你提交任务时，线程池队列已满，这时会发⽣什么
            - 如果你使⽤的LinkedBlockingQueue，也就是⽆界队列的话，没关系，继续添加任务到阻塞队列中等待执⾏，因为LinkedBlockingQueue  
            可以近乎认为是⼀个⽆穷⼤的队列，可以⽆限存放任务
            - 如果你使⽤的是有界队列⽐⽅说ArrayBlockingQueue的话，任务⾸先会被添加到ArrayBlockingQueue中,ArrayBlockingQueue满了，  
            则会使⽤拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。
    3. 拒绝任务,拒绝任务有两种情况：1. 线程池已经被关闭；2. 任务队列已满且maximumPoolSizes已满  
         1. new ThreadPoolExecutor.DiscardPolicy()：丢弃掉该任务，不进行处理
         2. new ThreadPoolExecutor.DiscardOldestPolicy()：丢弃队列里最近的一个任务，并执行当前任务
         3. new ThreadPoolExecutor.AbortPolicy()：直接抛出 RejectedExecutionException 异常
         4. new ThreadPoolExecutor.CallerRunsPolicy()：既不抛弃任务也不抛出异常，直接使用主线程来执行此任务
3. 线程结束的方式
    1. 正常运行结束
    2. 外部设置标志内部判断跳出
    3. Interrupt(in ner rui pu te)方法结束线程  
        1. 如使用了sleep,同步锁的wait,socket中的receiver,accept等方法时，会使线程处于阻塞状态。当调用线程的interrupt() 方法时会抛出InterruptException异常,通过代码捕获该异常，然后break跳出循环状态
        2. 线程未处于阻塞状态：使用isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会  
        置true，和使用自定义的标志来控制循环是一样的道理
    4. thread.stop()来强行终止线程,线程不安全
4. ThreadLocal
    * ThreadLocal为什么会发⽣内存泄漏?
        - ThreadLocal维护一个Map<ThreadLocal实例本身,value 是真正需要存储的 Object>
        - 也就是说ThreadLocal本身并不存储值，它只是作为⼀个key来让线程从ThreadLocalMap获取value,
        - ThreadLocalMap 是使⽤ ThreadLocal 的弱引⽤作为 Key 的，弱引⽤的对象在 GC 时会被回收
        - 如果⼀个ThreadLocal没有外部强引⽤来引⽤它，那么系统 GC的时候，这个ThreadLocal势必会被回收，  
        这样⼀来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value
        - 如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会⼀直存在⼀条强引⽤链：  
        Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远⽆法回收，造成内存泄漏
    * 底层为数组,key+value组成一个entity对象,根据该对象计算hash值,找到对应的位置,若key相同覆盖,若不相同往后一位查询是否有空位
    * 使用InheritableThreadLocal(in hai rui bo)创建实例,存入对象,子线程可以得到值
5. 常见问题
    1. 如何在两个线程之间共享数据?通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进⾏唤起和等待
    2. 单例模式的线程安全性?饿汉式(对象初始化时初始化),双检锁单例模式线程安全,懒汉式(调用时初始化)不安全
    3. spring默认时饿汉式,@lazy则是懒汉模式
    4. spring单例为什么没有安全问题?
        - spring使⽤ThreadLocal解决线程安全问题,ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，  
        !(可以把不安全的变量封装进ThreadLocal)。概括起来说，对于多线程资源共享的问题，同步机制采⽤了“以时间换空间”的⽅式，⽽ThreadLocal采⽤了  
        “以空间换时间”的⽅式。前者仅提供⼀份变量，让不同的线程排队访问，⽽后者为每⼀个线程都提供了⼀份变量，因此可以同时访问⽽互不影响
        - ⽆状态的Bean(⽆状态就是⼀次操作，不能保存数据。⽆状态对象(Stateless Bean)，就是没有实例变量的对象，不能保存数据，是不变类，  
        是线程安全的。)适合⽤不变模式，技术就是单例模式，这样可以共享实例，提⾼性能。
    5. Java线程和操作系统的关系
        现在的Java中线程的本质，其实就是操作系统中的线程。采用NPTL模型,每一个用户态线程都有一个内核的管理实体跟其对应,即一个进程下(用户空间)的线程  
        与其关联一个内核空间的管理线程,然后通过线程调度分配到不同的CPU上执行.本质上new一个线程就是重复上面的动作
    
    
    
### 锁
1. 锁类型
    1. 自旋锁,如果持有锁的线程能在很短的时间内释放资源,那么竞争锁资源的线程就不需要做内核态和用户态的切换,只需要等一等,就是  
         所谓的自旋,等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗
    2. 可重入锁,指一个线程进入一个锁方法,该方法调用的方法任然获取锁,synchronized属于可重入锁
    3. 独占锁只能有一个线程获取锁,ReentrantLock 就是以独占方式实现的互斥锁.也是悲观策略的一种
    4. 共享锁则允许多个线程同时获取锁,ReadWriteLock,属于乐观锁
    5. 重量级锁,Synchronized通过一个监视器锁monitor(班长)来实现,其底层则使用操作系统的互斥锁来实现,而操作系统与线程切换会  
        导致用户态转为核心态,状态转化时间长
    6. 轻量级锁介绍前需要普及一点,对于绝大部分轻量锁,在整个运行期间不存在竞争的.轻量锁使用CAS操作避免使用互斥锁,也避免了开销,  
        但是如果存在锁竞争,除了互斥锁开销还需要CAS,因此有竞争情况比重量锁更慢.加锁过程为进入同步块后,校验无锁后,虚拟机首先为当前线程的  
        栈帧建立一个锁记录的空间称为Lock Record,拷贝对象头中的标记对象,再进行CAS操作,将标记对象的指针指向Lock Record,再将Lock Record中  
        的owner指向标记对象(标记对象->Lock Record Lock Record中owner->标记对象)
    7. 偏向锁偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护,也就是该线程释放锁再次获得  
    锁。原因是因为大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。
    8. 分段锁,分段锁也并非一种实际的锁，而是一种思想 ConcurrentHashMap 是学习分段锁的最好实践
2. synchronized 它可以把任意一个非NULL的对象当作锁。他属于独占式的悲观锁，同时属于可重入锁
    1. 作用范围
        1. 作用于方法时，锁住的是对象的实例(this)
        2. 当作用于静态方法时，锁住的是Class实例
        3. 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块
    2. 核心组件
        1. Contention List:所有请求该锁的请求首先放置于该队列中
        2. Entry List: Contention中有资格成为候选者放入该队列
        3. OnDeck:任意时刻,只有一个线程正在竞争锁,该线程就是OnDeck
        4. Wait Set:调用Wait方法,线程阻塞的对象放置于此
        5. Owner:获得锁权限的线程
        6. !Owner:当前释放锁的线程
    3. 实现
        1. 一个线程线先会尝试自旋获取锁,如果获取不到会进入Contention,这能体现出synchronized是非公平的
        2. 因为并发情况下Contention会进行大量CAS访问,为了降低对尾部元素竞争,jvm会将一部分Contention放入Entry
        3. Owner解锁时,会将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList中的某个线程为OnDeck线（一般  
          是最先进去的那个线程）
        4. Owner 线程并不直接把锁传递给OnDeck线程,而是把锁竞争的权利交给OnDeck,OnDeck需要重新竞争锁,这也是非公平的
        5. OnDeck线程获取到锁资源后会变为Owner,而没有得到锁资源的仍然停留在 EntryList中。
        6. 如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中直到某个时刻通过 notify或者 notifyAll 唤醒，会重新进去 EntryList 中
    4. 注意
        1. 每个对象都有个monitor(mou le te)(班长)对象加锁就是在竞争monitor对象，代码块加锁是在前后分别加,上monito和 monitorexit 指令来实现的，  
        方法加锁是通过一个标记位来判断的
        2. synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。
        3. JDK6引入适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高
        4. JDK7引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。
        5. 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀
    5. 与ReentrantLock区别
        1. ReentrantLock是Api级别的,synchronized是JVM级别的
        2. synchronized是同步阻塞,悲观。lock是同步非阻塞,乐观
        3. lock会自动释放锁,而Lock需要手动
        4. Lock可以实现读写锁
3. ReentrantLock(re an quan lock)继承Lock并实现接口中定义的方法,是一种可重入锁,除了可完成synchronized的工作外,还可相应中断锁,轮询锁请求,定时锁
    1. ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作，与 synchronized 会被 JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁
    2. ReentrantLock 相比 synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用 ReentrantLock
    3. 需要再finally中进行解锁操作
    4. ReentrantReadWriteLock.ReadLock|ReentrantReadWriteLock.WriteLock又一个ReentrantReadWriteLock生成,读锁为共享锁,
    且当没有读锁发生时共享,读锁为排他锁
    5. 在ReentrantLock的默认无参构造方法中，创建的是非公平锁,使用的是其中的内部类NonfairSync,继承AbstractQueuedSynchronizer
        * NonfairSync
            - NonfairSync就是以个AQS,上锁本质上就是尝试设置state=1
            - 线程只要执行lock请求,就会立马尝试获取锁,不会管AQS当前管理的等待队列中有没有正在等待的线程,这种操作是不公平的，没有先来后到
            - CAS操作得比较与交换(compareAndSetState)利用unsafe包的cas操作，unsafe包类似一种java留给开发者的后门，  
            可以用来直接操作内存数据，并且保证这个操作的原子性
            - 当第一次获得锁失败,再次判断,若还是不行,判断是否为重入锁情况(获取锁线程是否为当前线程),若是则state+1
            - 当获取失败且部位重入锁情况下,创建一个互斥得节点,放入Node链表尾部
            - 然后让该节点判断,首先判断上个节点是否为头节点,若是得话说明是队列中最大优先级节点,不必挂起,再次尝试获取锁
            - 若不是,检查前置节点值
                * 前置节点是-1，返回true表示线程可挂起
                * 前置节点大于0表示前置节点已经取消，那么进行跳过前置节点的操作，做链表的基本删除节点操作
                * 如果前置节点还是0,表示前置节点Node的waitStatus是初始值，需要设置为-1，然后外层循环重新执行  
                shouldParkAfterFailedAcquire方法，即可挂起当前线程
            - 最后阻止线程,等待唤醒
        * FairSync公平锁
            - 与非公平锁最大区别在第一次上锁时会判断队列中是否有等待得线程,若没有才会尝试获取锁
4. 线程方法
    1. 线程等待（wait）
    2. 线程睡眠（sleep）
    3. 线程让步（yield)(一流的)
    4. 线程中断（interrupt）
    5. 等待其他线程终止(Join)在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞状态，回到另主线程结束，当前线程  
    再由阻塞状态变为就绪状态，等待 cpu 的宠幸
    6. 线程唤醒（notify）
5. 术语
    1. cpu巧妙通过时间片轮换,当轮换时任务的状态保存及再加载, 这段过程就叫做上下文切换
    2. 上下文是指某一时间点CPU 寄存器和程序计数器的内容
    3. 寄存器 是CPU 内部的数量较少但是速度很快的内存（与之对应的是CPU 外部相对较慢的RAM 主内存）
    4. 程序计数器 是一个专用的寄存器，用于表明指令序列中CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置
6. volatile(wo了头)提供了一种稍弱的同步机制(不加锁),用来确保将变量的更新操作通知到其他线程
    1. 变量可见:保证所有线程可见,值一个线程修改了值,那么新的值对于其他线程是可见的,且每次读取必须刷新内存种最新值
    2. 禁止重排序:禁止了JVM的指令重排序
    3. 对于非volatile的变量读写,每个线程会先拷贝到当前CPU缓存,多个CPU拷贝的值可能会不一样
    4. volatile的变量读写,会直接从内存种读取,跳过CPU缓存这一步
    5. 不支持i++,因为先读取值,再+1,再回写
    6. 所以volatile只支持单纯的赋值
7. ThreadLocal线程本地存储,在一个线程的调用过程,进入多个方法种起作用,减少一个线程内多个函数或组件参数的复杂度
8. CAS(比较并交换)
    1. 包含3个参数(V 需要更新的变量,E 旧值,N 新值),且当V ==E 才会V=N
    2. 若不相等,说明其他线程已经更新,就会返回V,也就是真实值
    3. 运许失败后重试,知道成功,比如使用version字段,是乐观锁
    4. ABA问题,某个线程将值从1变为0,然后再次为1.对于其他线程有可能发生在一次操作中，为感知到已变化过,version无此问题
9. AQS 抽象的队列同步器,AQS定义了一套多线程访问共享资源的同步框架,如ReentrantLock(rv 安全 lock),Semaphore(3 mo fou),CountDownLatch
    1. 由一个先进先出线程队列(多线程阻塞竞争阻塞时放入此队列)和一个state(资源)构成
    2. 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，  
    那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中
    3. CLH队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。AQS是将每一条请求共享资源的线程封装成  
    一个CLH锁队列的一个结点（Node），来实现锁的分配。
    4. 用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒
    5. 流程
        * 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；
        * 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
        * quireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。  
        如果在整个等待过程中被中断过，则返回true，否则返回false。
        * 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上
    6. AQS定义两种资源共享方式,如ReentrantLock的独占式,和如Semaphore,CountDownLatch共享式
    7. AQS 只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现
    8. status在不同情况含义不同
        * 在ReentrantLock中，表示AQS的锁是否已经被占用获取，0：没有，>=1：已被获取,当大于1时表示被同一线程多次重入锁
        * 在CountDownLatch中，表示计数还剩的次数，当到达0时，唤醒等待线程。
        * 在Semaphore中，表示AQS还可以被获取锁的次数，获取一次就减1，当到达0时，尝试获取的线程将会阻塞
    9. AbstractQueuedSynchronizer简称AQS，是⼀一个⽤用于构建锁和同步容器器的框架
10. 分布式锁
    1. Zookeeper：基于zookeeper瞬时有序节点实现的分布式锁
        - 每个客户端对某个功能加锁时，在zookeeper上的与该功能对应的指定节点的⽬录下，⽣成⼀个唯⼀的瞬时有序节点。判断是否获取锁的⽅式很简  
          单，只需要判断有序节点中序号最⼩的⼀个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁  
          ⽆法释放，⽽产⽣的死锁问题
        - 锁安全性⾼，zk可持久化，且能实时监听获取锁的客户端状态。⼀旦客户端宕机，则瞬时节点随之消失，zk因⽽能第⼀时间释放锁。  
        这也省去了⽤分布式缓存实现锁的过程中需要加⼊超时时间判断的这⼀逻辑
        - 性能开销⽐较⾼。因为其需要动态产⽣、销毁瞬时节点来实现锁功能。所以不太适合直接提供给⾼并发的场景使⽤,对可靠性要求⾮常⾼，  
        且并发程度不⾼的场景下使⽤。如核⼼数据的定时全量/增量同步等
    2. redis
        - redis分布式锁即可以结合zk分布式锁锁⾼度安全和memcached并发场景下效率很好的优点，其实现⽅式和memcached类似，  
        采⽤setnx即可实现。需要注意的是，这⾥的redis也需要设置超时时间，以避免死锁。可以利⽤jedis客户端实现。 
        - redis集群情况下,可能出现锁复制不及时等情况,还是使用redisLock之Redisson落地实现 
        

### 基础
1. 反射
    1. 动态语言指程序运行期间可以改变结构,可以增加新得函数,删除已有函数,从反射角度,java属于半动态语言
    2. Person p=new Student(); 编译时类型为Person，运行时类型为Student
    3. 获取字节码对象三种方式(不管某个类被加载多少次，对应堆内存中的class对象始终只有一个)
        * ArrayList.class JVM将使用类装载器，将类装入内存(前提是:类还没有装入内存)，[不做类的初始化工作]，返回Class的对象。  
        当类被加载成.class文件时，此时Person类变成了.class，在获取该字节码文件对象，也就是获取自己， 该类处于字节码阶段。
        * list.getClass()[对类进行静态初始化、非静态初始化]；返回引用运行时真正所指的对象(子对象的引用会赋给父对象的引用变量中)所属的类的Class的对象。  
        通过类的实例获取该类的字节码文件对象，该类处于创建对象阶段
        * Class.forName("类的全路径")[装入类，并做类的静态初始化，返回Class的对象]。直接获取到一个类的字节码文件对象，  
        此时该类还是源文件阶段，并没有变为字节码文件。
2. clone()方法需要类实现Cloneable并重写clone()
3. 树遍历
    1. 前序 根->左->右
    2. 中序 左->根->右
    3. 后序 左->右->根
4. GET and POST区别
    - 根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的
    - GET方式提交的数据最多只能是1024字节，理论上POST没有限制，可传较大量的数据
    - POST相对安全不能做缓存
    - GET在浏览器回退时是无害的，而POST会再次提交请求
    - 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200,而对于POST，浏览器先发送header，服务器响  
    应100 continue，浏览器再发送data，服务器响应200 ok
5. I/O模型
    * 进程切换:为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换  
    从一个进程的运行转到另一个进程上运行是很耗资源
    * 阻塞:正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，  
    则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态.当进程进入阻塞状态，是不占用CPU资源的。
    * IO访问流程:等待数据准备,将数据从内核拷贝到进程中|socket流:通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区,  
    把数据从内核缓冲区复制到应用进程缓冲区
    * 分类
        - 阻塞IO
        - 非阻塞IO
        - 多路复用IO:epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，  
        这样在用户空间和内核空间的copy只需一次
        - 异步 I/O
6. web服务
    - servlet
        * 生命周期
            - init()方法仅执行一次init()方法，它是在服务器装入Servlet时执行的，可以配置服务器，以在启动服务器或客户机首次访问  
            Servlet时装入Servlet
            - service() 它是Servlet的核心，每当一个客户请求一个HttpServlet对象，该对象的Service()方法就要调用，而且传递给这个  
            方法一个“请求”（ServletRequest）对象和一个“响应”（ServletResponse）对象作为参数
            - destroy()方法,仅执行一次，在服务器端停止且卸载Servlet时执行该方法
        * Servlet容器默认采用单实例多线程的方式来处理请求，这样减少产生Servlet实例的开销，提升了对请求的响应时间  
    - cookie and session
        * cookie存在客户端,session存在服务端
        * session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session创建完之后，会把session的id发送给客户端，  
        客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid之后，  
        在内存找到与之对应的session这样就可以正常工作了
7. Http
    *  Http与Https的区别
        1. HTTP 的URL 以http:// 开头，而HTTPS 的URL 以https:// 开头
        2. HTTP 是不安全的，而 HTTPS 是安全的
        3. HTTP 标准端口是80 ，而 HTTPS 的标准端口是443
        4. 在OSI 网络模型中，HTTP工作于应用层，而HTTPS 的安全传输机制工作在传输层
        5. HTTP 无法加密，而HTTPS 对传输的数据进行加密
        6. HTTP无需证书，而HTTPS 需要CA机构wosign的颁发的SSL证书
    * HTTPS工作原理
        1. 首先HTTP请求服务端生成证书,客户端对证书的有效期校验
        2. 客户端如果校验通过后，就根据证书的公钥生成私钥
        3. 消息体产生的后，对它的摘要进行MD5（或者SHA1）算法加密，此时就得到了RSA签名
        4. 发送给服务端，此时只有服务端（RSA私钥）能解密
        5. 解密得到的随机数，再用AES加密，作为密钥
    * 一次完整的HTTP请求所经历的7个步骤
        1. 建立TCP连接
        2. Web浏览器向Web服务器发送请求行
        3. Web浏览器发送请求头
        4. Web服务器应答
        5. Web服务器发送应答头
        6. Web服务器向浏览器发送数据
        7. Web服务器关闭TCP连接
    * Http1.1
        1. HTTP 1.1的持续连接
        2. HTTP 1.1增加host字段
        3. HTTP/1.1加入了一个新的状态码100,用来节约带宽
    * 与UDP
        1. 首先 UDP 是不需要和 TCP一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。并且也只是数据报文的搬运工，  
        不会对数据报文进行任何拆分和拼接操作
        2. UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能
        3. 首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠,并且收到什么数据就传递什么数据，  
        并且也不会备份数据，发送数据也不会关心对方是否已经正确接收到数据了,再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，  
        一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整
8. socket
    1. Socket是什么？ socket通常称为“套接字”，用于描述IP地址和端口，是一个通信链的句柄。应用程序通过套接字向网络发出请求或应答网络请求
    2. 通信双方如何进行端口绑定?通常服务端启动时会绑定一个端口提供服务，而客户端在发起连接请求时会随机分配一个端口号
9. 跨域 设置CorsConfiguration,设置Origin,Header,Method
10. 设计模式6大原则
    1. 开闭原则:对扩展开放，对修改关闭
    2. 里氏代换原则:任何基类可以出现的地方，子类一定可以出现
    3. 依赖倒转原则:针对接口编程，依赖于抽象而不依赖于具体
    4. 接口隔离原则:使用多个隔离的接口，比使用单个接口要好
    5. 迪米特法则，又称最少知道原则:一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。
    6. 合成复用原则:尽量使用合成/聚合的方式，而不是使用继承
        
###Mybatis
1. 一级缓存
    1. 一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，  
    而是直接从缓存中获取，一级缓存最多缓存1024条SQL
    2. 发出一个新得sql查询,查询结果写入SqlSession,结构为map(key:MapperID+offset+limit+Sql+所有的入参,value:信息)
    2. 如果中间出现commit操作（修改、添加、删除），本sqlsession中的一级缓存区域全部清空
2. 二级缓存
    1. 二级缓存的范围是mapper级别（mapper同一个命名空间）
    2. 所有的查询操作，在CacheExecutor中都会先匹配缓存中是否存在，不存在则查询数据库
    3. key：MapperID+offset+limit+Sql+所有的入参
3. mybatis#{}和${}的区别是什么
    1. mybatis#{}是预编译处理，${}是字符串替换
    2. Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值；
    3. Mybatis 在处理${}时，就是把${}替换成变量的值
    4. 使用#{}可以有效的防止 SQL 注入，提高系统安全性
    5. 数据库接受到sql语句之后，需要词法和语义解析，优化sql语句，制定执行计划。这需要花费一些时间,如果每次都需要经过上面的  
    词法语义解析、语句优化、制定执行计划等，则效率就明显不行了。为了解决上面的问题，于是就有了预编译
4. 传统JDBC弊端
    1. jdbc没有使用连接池
    2. PreparedStatementd预编译对变量序号设置123,不利于维护
    3. sql语句修改需要整体编译,然后result需要硬编码
5. 流程
    1. SqlSessionFactoryBuilder#build解析XML文件获取数据库源生成一个xNode对象
    2. 跟据xml,获取所有mapper(4种注入mapper class resource file package)所有sql语句封装成一个MappedStatement的类
    3. 根据条件创建执行器,默认由三种simple(默认),reuse,batch
    4. 查询就是访问对应的Statement,然后根据Statement生成BoundSql对象
    5. 根据BoundSql生成缓存Key
    6. 根据缓存执行器(缓存执行器为三个执行器的父类)查找对象
    7. 若没有,则按照原生JDBC一样,创建wfgconnection,设置PreparedStatementd,执行sql
    8. 返回结果根据对象封装对象
###netty
1. 0拷贝
    1. Netty的接送和发送ByteBuffer使用堆外直接内存进行Socket读写,不要进行字节缓存区的二次拷贝
        * 读取本地文件,通过传统网络发送需要4次内容复制
            1. 从磁盘复制数据到内核态内(DMA操作,无需消耗CPU)
            2. 从内核态内存复制到应用缓冲区中,该步骤完成读取数据(copy动作,需要消耗CPU)
            3. 然后从应用缓冲区中内存复制到网络驱动的内核态内存(copy动作,需要消耗CPU)
            4. 后是从网络驱动的内核态内存复制到网卡中进行传输,该步骤完成发送内容
        * 使用netty则直接取消了应用缓存区,直接将读取到的内核内数据直接复制到写出的内核数据中
    2. 传统模式使用堆内存进行Socket读写,JVM需要将堆内存Buff拷贝到直接内存,再写入Buff
    3. Netty可以组合多个Buff聚合成一个Buff
    4. Netty的文件传输采用了transferTo方法,可以直接将文件缓存区的数据发送到Channel,避免了循环write导致的内存拷贝问题
2. 内存池,特别时堆外内存分配回收十分耗时,Netty采用了基于内存池的缓存区重用机制
3. NIO采用多个并行的串行化,实现了局部无锁化的串行线程比一个队列多个工作线程模型更优
4. Netty RPC
    1. 流程,RPC就是将3-8进行封装。java一般使用动态代理方式实现远程调用
        1. 生产者使用zk注册,消费端可以通过zk获取地址
        2. 消费方以本地调用方式调用服务
        3. Client Stub(客户端存根)用于存放服务端地址消息,将客户端的组装方法,参数打包成网络消息,,也便是一个地址,很长的一段URL
        4. 找到服务地址,再通过网络远程发送给服务方
        4. Server Stub 收到消息后进行解码
        5. Server Stub 根据解码结果调用本地方法
        6. 本地服务执行并将结果返回给 Server Stub
        7. Server Stub 将返回结果打包成消息并发送至消费方
        8. Client Stub 接收到消息，并进行解码
        9. 服务消费方得到最终结果。
    2. 消息结构
        1. 消费端请求结构:接口名称+方法名+参数类型和参数值+超时时间+ requestID(标识唯一请求 id)
        2. 服务端返回结构:返回值+状态code+requestID
    3. 通讯过程
        1. 调用使用netty的channel.writeAndFlush()方法来发送消息二进制串,这个方法从整个调用过程来说是异步的,不知道何时返回  
        结果,所以会向下运行(问题1)
        2. 多线程进行方法调用,一个Client下有一个Socket,此时A线程先进来发送消息,再是B线程,有可能B的结果先返回,怎么保证对于(问题2)
        3. 问题2:client每次通过Socket调用前需要生成唯一的RequestId,返回将其带回,通常使用AtomicLong累计生成
        4. 问题1: 
            1. 将处理结果的回调对象callback存放到全局ConcurrentHashMap里面put(requestID, callback)
            2. 当线程channel.writeAndFlush()发送消息后，紧接着执行 callback 的 get()方法试图获取远程返回的结果
            3. 在 get()内部，则使用 synchronized 获取回调对象 callback 的锁，再先检测是否已经获取到结果，如果没有，然后调用 callback 的 wait()方法，  
            释放callback 上的锁，让当前线程处于等待状态
            4. 服务端处理完成后,将response发给客户端,客户端Socket连接上专门监听消息的线程收到消息
            5. 分析response,获取requestId,再从ConcurrentHashMap通过id获得callback对象
            6. 再通过synchronized获取CallBack的锁,再将返回的结果设置到CallBack对象中
            7. 最后通过callback.notifyAll()唤醒前面处于等待状态的线程
    4. MRI  Java 远程方法调用，即 Java RMI是 Java 编程语言里，一种用于实现远程过程调用的应用程序编程接口
5. Dubbo
    * 协议
        - dubbo:单一长连接和 NIO 异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议 TCP，异步，Hessian 序列化
        - RMI:采用JDK标准RMI协议实现,传输协议TCP
        - webservice
        - HTTP: 基于 Http 表单提交的远程调用协议，使用 Spring 的 HttpInvoke 实现。多个短连接，传输协议 HTTP
        - hessian: 集成 Hessian 服务，基于 HTTP 通讯，采用 Servlet 暴露 服务，Dubbo 内嵌 Jetty 作为服务器时默认实现
        - redis： 基于 redis 实现的 RPC 协议
    * Dubbo 在安全机制方面是如何解决的?Dubbo 通过 Token 令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。  
    Dubbo 还提供服务黑白名单，来控 制服务所允许的调用方
    * RPC是一种计算机通信协议,远程过程调用。该协议运行一台计算机的程序调用另外一台计算机的子程序
    * dubbo 通信协议 dubbo 协议为什么采用异步单一长连接?因为服务的现状大都是服务提供者少，通常只有几台机器,而服务的消费者多，可能整个网站都在访问该服务  
    比如 customer-api 的提供者只有 6 台提供者，却有上百台消费者，每天有 1.5 亿次调用，如果采用常规的 hessian 服务，服务提供者很容易就被压跨  
    通过单一连接，保证单一消费者不会压死提供者,长连接，减少连接握手验证等，并使用异步 IO，复用线程池，防止 C10K 问题
    * Dubbo模块组成
        - Provider:提供API,实现API,暴露服务,服务本地,注册中心 注册
        - Consumer:拿接口名从注册中心获取服务地址,调用服务
        - Registry:保存服务配置,(服务名:List<URL>)
        - RpcProtocol:基于tomcat的Http服务,基于Netty的DubboProtocol
        - Framework:框架实现
    * 服务引入的三种方式
        - 本地引入,生产者自己掉自己的服务,不需要网络开销
        - 直连远程引入服务
        - 注册中心引入远程服务 
    * 服务暴露
         - springIOC容器刷新完成后调用onApplicationEvent(监听器)
         - 然后调用export(),主要就是检查配置,确认是否要暴露服务,然后组装个大Map,在转化为URL对象
         - 然后将URL封装成一个Invoker暴露服务，包括暴露到本地的服务(injvm协议,是一个伪协议,不开启端口,不发起远程调用,  
         只在jvm内直接关联)和远程的服务
            - 为什么要封装成invoker?想屏蔽调用的细节，统一暴露出一个可执行体
            - 为什么要搞个本地暴露呢?暴露的本地服务在内部调用的时候可以直接消费同一个 JVM 的服务避免了网络间的通信
         - 第三步是注册服务至注册中心。根据invoker进行服务暴露,打开端口,然后根据URL的registry具体实现类,将服务注册上去
         - SPI扫描的类来实现不同的协议,和dubbo自己的AOP  
    * 服务引用
        -  默认通过懒汉式加载对象,以服务引入的入口就是 ReferenceBean 的 getObject 方法,如果没有就执行Init()
        - 简述一下就是先检查配置，通过配置构建一个 map ，然后利用 map 来构建 URL ,再通过 URL 上的协议利用自适应扩展机制调  
        用对应的 protocol.refer 得到相应的 invoker 。
        - 如果是走本地的话，那么直接构建个走本地协议的 URL 然后进行服务的引入
        - 远程会向注册中心注册自己的信息，然后订阅注册中心相关信息，得到远程 provider的 ip 等信息，再通过netty客户端进行连接
    * dubbo负载均衡策略
        - dubbo的负载均衡策略，主体向外暴露出来是一个接口，名字叫做loadBlace,抽象类为AbstractLoadBlance
        - 核心方法为[<T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) throws RpcException;]
        - 里面判断invokers,调用者集合,若为空返回空,若为一个直接返回第一个,若多个则调用doSelect(参数一致)
        - 我们写不同的负载均衡策略便是重写不同的doSelect方法
        - 默认自带算法一致性Hash均衡算法、随机调用法(默认)、轮询法、最少活动调用法
        - 随机调用法:完全随机
        - 轮询法:轮询调用并不是简单的一个接着一个依次调用，它是根据权重的值进行循环的
        - 最少活动调用法:找到最少活跃数(在代码层反应就是：active的值)的调用者
        - 一致性Hash均衡算法:需要配置参数hash.arguments(根据调用方法的那些参数生成key),hash.nodes:节点的副本数
        - @Reference(loadbalance= "策略名")
    * SPI
        - javaSPI就是通过ServiceLoader加载一个接口时,有多个实现类,在resource下建立META-INFO.Services,里面创建全路径名接口的  
        一个文件,里面配置实现类的全路径名,这样加载时候就会加载出这个实现类,当需要扩展时,写自己的扩展实现类,然后配置就会变成  
        你的扩展实现类,比如jdbc,mysql,Oracle会有不同的配置文件指向不同实现类
        - Dubbo的SPI的扩展
            1. 配置文件支持key=value方式,指定特定的实现类.且在里面可以加入包装类
            2. 通过代理的方式,将代理对象通过参数传入包装类,进行AOP,这也是Dubbo扩展的AOP 
            3. Dubbo的IOC则是对需要注入的接口传入URL,然后在方法上加入@Adaptive(value = "URL配置里面对应某个属性的KEY名")  
            然后根据传入的url中属性的key名可以找到对应的实现类
            
### kafka
1. 构成
    1. broker:kafka服务器,负责消息存储和转发
    2. topic:消息类别
    3. partition:topic分区,一个topic可以有多个partition,topic消息保存再各个partition上
    4. offset:消息日志中的位置,可以理解是消息再partition上的偏移量,也代表是消息的唯一序号
    5. producer:生产者
    6. consumer:消费者
    7. consumer group:消费分组
    8. zookeeper:保存broker,topic,partition等数据,还负责故障发现,partition选举,负载均衡
2. partition
    1. partition中每条Message包含三个属性 offset,messageSize,data
    2. partition物理上由多个segment文件组成,每个segment相等,顺序读写
    3. kafka为每个segment中的数据文件建立了索引,采用稀疏存储，每隔一定字节建立索引
    
    
    
### RocketMq
1. rocketMq分为pull模式和Push模式,push通过长轮询得pull实现
2. RocketMq定义了一个ProcessQueue；,来解决监控和控制,比如:如何得知当前消息堆积的数量,如何重复处理某些消息,如何延迟处理某些消息
    * ProcessQueue对象里主要的内容是一个TreeMap和一个读写锁
        - TreeMap里以MessageQueue的Offset作为Key，以消息内容的引用为Value，保存了所有从MessageQueue获取到，但是还未被处理的消息
        - 读写锁控制着多个线程对TreeMap对象的并发访问
    * ProcessQueue还可以辅助实现顺序消费的逻辑
    * 一个Topic会有多个MessageQueueOffset是指某个Topic下的一条消息在某个MessageQueue里的位置，通过Offset的值可以定位到这条消息
        - push模式下不用关心OffsetStore的事，但是如果PullConsumer，我们就要自己处理OffsetStore了,默认用的Push
        - offset对于每个队列都是自己下从0开始定义的,不是总数
3. 消息发送同步发送、异步发送,单向发送,还支持延时发送和发送事务
    * 延时发送:Broker收到这类消息后，延迟一段时间再处理，使消息在规定的一段时间后生效,时间为仅支持设值的时间长度
    * 对事务的支持:是指发送消息事件和其他事件需要同时成功或同时失败
        - 发送方向RocketMQ发送“待确认”消息
        - RocketMQ将收到的“待确认”消息持久化成功后，向发送方回复消息已经发送成功，此时第一阶段消息发送完成
        - 发送方开始执行本地事件逻辑
        - 发送方根据本地事件执行结果向RocketMQ发送二次确认（Commit或是Rollback）消息
        - RocketMQ收到Commit状态则将第一阶段消息标记为可投递，订阅方将能够收到该消息；
        - 收到Rollback状态则删除第一阶段的消息，订阅方接收不到该消息。
        - 如果出现异常情况，步骤4）提交的二次确认最终未到达RocketMQ,服务器在经过固定时间段后将对“待确认”消息、发起回查请求
        - 发送方收到消息回查请求通过检查对应消息的本地事件执行结果返回Commit或Roolback状态
        - RocketMQ收到回查请求后,继续按照上述逻辑处理

4. NameServer维护每个机器的角色、IP地址配置信息、状态信息，其他角色都通过NameServer来协同执行
    * NameServer是整个消息队列中的状态服务器，集群的各个组件通过它来了解全局的信息,，各个角色的机器都要定期向NameServer  
    上报自己的状态，超时不上报的话，NameServer会认为某个机器出故障不可用了，其他的组件会把这个机器从可用列表里移 
    * NameServer本身是无状态的，也就是说NameServer中的Broker、Topic等状态信息不会持久存储，都是由各个角色定时上报并存储到内存中的
    * RocketMQ各个模块间的通信，可以通过发送统一格式的自定义消息,采用自己定义了一个通信协议，使得模块间传输的二进制消息和有意义的内容之间互相转换
    * NameServer的功能虽然非常重要，但是被设计得很轻量级，代码量少并且几乎无磁盘存储，所有的功能都通过内存高效完成
    * RocketMQ基于Netty对底层通信做了很好的抽象，使得通信功能逻辑清晰
5. Broker是RocketMQ的核心,包括接受生产者消息,处理消费者请求、消息的持久化存储、消息的HA机制以及服务端过滤功能等
    * 磁盘读写,顺序写速度可以达到600MB/s,而磁盘随机写的速度只有大概lOOKB/s
    * RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成的
        - ConsumeQueue本质队列里面放的不是数据,而是个指针,指向的是物理存储地址，也就是CommitLog里面对应的数据
        - 在CommitLog中，一个消息的存储长度是不固定的，RocketMQ采取一些机制，尽量向CommitLog中顺序写，但是随机读
        - Rocket分布式中,分为Master(brokerId=0)支持读写,而Slave(brokerId>0)仅支持读
        - 所以消费者连接Slave,而生产者连接Master会大大提高效率
    * 刷盘方式分为同步刷盘和异步刷盘
        * 异步刷盘消息只被写入叶缓存,当消息堆积到一定程度后批量写入
        * 同步刷盘是当返回消息状态为成功时,已经完成磁盘写入
    * Master复制到Slave也分为同步复制与异步复制
6. rocketMq默认不能进行全局顺序消费,若要满足全局顺序消费,需要将Top下的读写队列设置为1,简单来说就是单线程处理
7. 若要满足部分顺序消费,则将一个消息组放入一个消息队列中即可,消费端通过MessageQueueSelector来选择发往那个消息队列,消费端  
通过MessageListenerOrderly类来解决单MessageQueue的消息被并发处理的问题
8. 优化
    * 消息过滤
        - 通过Tag进行过滤
        - 在启动Broker前在配置文件里加上filterServer­Nums = 3这样的配置,消费端实现MessageFilter类
    * 提高Consumer处理能力
        - 增加Consumer实例的数量来提高并行度
        - 设置Consumer的consumeMessageBatchMaxSize这个参数，默认是1，如果设置为N，在消息多的时候每次收到的是个长度为N的消息链表
        - 检测延时情况，跳过非重要消息
    * Consumer负载均衡默认五种,也可自己实现
9. 构成
    1. Nameserver,无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。
    2. Producer 消息生产者，负责发消息到Broker。
    3. Broker 就是MQ本身，负责收发消息、持久化消息等。
    4. Consumer 消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。
10. 负载均衡
    1. 生产者默认每个维护一个index,每次取节点递增,index取余broker,然后找到对应的broker存放消息,自带容错策略
    2  消费者采用的是平均分配算法来进行负载均衡。
    
    
### 数据库
1. 存储引擎包含InnoDB,MyIsam,memory,Archive,Federated等等
2. InnoDB(B+树)
    1. 5.6默认为InnoDB
    2. 遵循ACID模式,行级别锁,一致性读
    3. 底层为B+树,每个节点对应InnoDB的一个page,每个page大小是固定的,其中非叶子节点只有键值,叶子节点包含完整数据
    4. B树为了减少磁盘IO,变成又矮又胖的,底层磁盘块数据也是按顺序存放,但是非叶子节点也存放数据,若数据大的时候每个中间的磁盘块  
    的度,即导航的位置会变小,所以B+只在叶子节点存数据。且叶子节点通过双向链表连接,更方便的范围查询
3. InnoDB构成
    1. 内存池客户端读取数据时，如果数据存在于缓冲池中，客户端就会直接读取缓冲池中的数据，否则再去磁盘中读取；对于数据库中  
    的修改数据，首先是修改在缓冲池中的数据,然后等到阈值批量提交。维护该查询缓存对应的内存区域。从MySQL 5.7.20开始，不推荐  
    使用查询缓存，并在MySQL 8.0中删除
        * 缓冲区分为两块,第一块为控制页括该页所属的表空间编号、页号、缓存页在Buffer Pool中的地址、链表节点信息、一些锁信息以及LSN(日志序列位置)信息  
        第二块就是缓冲的数据,控制页和缓存页是一一对应的,其中控制块被存放到 Buffer Pool 的前边，缓存页被存放到 Buffer Pool 后边
        * 在Buffer Pool中被修改的页称为脏页，脏页并不是立即刷新，而是被加入到flush链表中，待之后的某个时刻同步到磁盘上
        * 为了快速定位某个页是否被加载到Buffer Pool，使用表空间号 + 页号作为key，缓存页作为value，建立哈希表
        * 缓冲区淘汰原则采用LRU(最久未使用淘汰),存放一个链表,最新使用的放入表头.整个链表分为两节,一节储存使用率不高的old区  
        一节使用率高的young区,当磁盘上的某个页面在初次加载到BufferPool中的某个缓存页时，该缓存页对应的控制块会被放到old区域的头部,   
        这样解决了一次大量读取会刷掉热数据和数据库预读引起的问题
        * 因为一页有多条数据,全表扫描会读取一页多次,所以依然会把old放入young,所以提出时间概念,第一次访问该页会记录时间,如果后续  
        访问该页时间短,也不会触发移动
        * 只有被访问的缓存页位于young区域的1/4的后边，才会被移动到LRU链表头部
        * 我们可以通过指定innodb_buffer_pool_instances来控制Buffer Pool实例的个数，每个Buffer Pool实例中都有各自独立的链表，互不干扰
    2. 后台线程
        1. Master Thread 主要负责将缓冲池中的数据异步刷新到磁盘中，除此之外还包括插入缓存、undo 页的回收等
        2. IO Thread 是负责读写 IO 的线程
        3. Purge(清除)Thread 主要用于回收事务已经提交了的 undo log
        4. PagerCleanerThread 是新引入的一个用于协助 Master 4 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞
    3. 存储文件:存储数据都是按表空间进行存放的，默认为共享表空间，存储的文件即为共享表空间文件（ibdata1)
4. InnoDb逻辑存储结构主要包括表空间，段，区，页，行组成
    1. 表空间共有两种，一种是共享表空间，另一种是独占表空间共享表空间为ibdata1。如果设置了参数innodb_file_per_table,  
    则每一张表都有一个独立的物理文件  
        * 我们知道MySQL中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储视图的时候是不需要存储真实的数据的，  
        只需要把它的结构存储起来就行了。和表一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下边，只会存储一个视图名.frm的文件
        * 整个MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面
        * 独立表空间中第一个页的头文件中存有最大索引值得下一个应分配值
        * 系统表里会存放很多元数据,如表对应的每一个列的类型是什么,该表有多少索引，每个索引对应哪几个字段，该索引对应的根页面  
        在哪个表空间的哪个页面等等,这些在插入时候,修改等等时候会需要用到
    2. 表空间有段组成，段分为数据段和回滚段
        * 存放叶子节点的区的集合就算是一个段,存放非叶子节点的区的集合也算是一个段
        * 段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页面以及一些完整的区组成
    3. 区是表空间的结构单元,对于16KB的页来说，连续的64个页就是一个区大小为1M。
        * 为了防止不同物理空间上存放太远的页进行随机I/O过于慢,所以引出区
        * 碎片区:在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，可以是叶子节点的页+非叶子节点的页,当某个  
        段占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间
    4. 页是MySQL中 磁盘和内存交互的基本单位，也是MySQL是管理存储空间的基本单位，默认大小为16KB。一次读写最小也是16kb
        * Mysql规定一个页中至少存放两行记录,如果我们一条记录的某个列中存储的数据占用的字节数非常多时，该列就可能成为溢出列
        * 页结构
            1. FileHeader,文件头部,页的一些通用信息,比方说这个页的编号是多少，它的上一个页、下一个页是谁,页的类型,比如索引页，也就是我们  
            所说的数据页,也就是存放记录的页
            2. PageHeader,页面头部,数据页专有的一些信息,比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等
            3. Infimum + Supremum,最小记录和最大记录,两个虚拟的行记录,也会写入行格式中记录头信息的heap_no中,所以heap_no默认实际数据从2开始
            4. UserRecords,用户记录,实际存储的行记录内容,行格式存储部分
            5. FreeSpace,空闲空间,页中尚未使用的空间,当插入时,申请空间写入后分配到UserRecords,且空闲用完也就说明该页用完,再次插入  
            只能申请新的页
            6. PageDirectory,页面目录,页中的某些记录的相对位置
            7. FileTrailer,文件尾部,校验页是否完整,防止内存同步磁盘时断电等情况	
        * 页目录(PageDirectory)
            1. 将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组
            2. 每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned属性表示该记录拥有多少条记录，也就是该组内共有几条记录。
            3. 将每个组的最后一条记录的地址偏移量单独提取出来按顺序存储到靠近页的尾部的地方,这就叫页目录
            4. 对于最小记录所在的分组只能有 1 条记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中记录的条数范围只能在是 4~8 条之间
            5. 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录
            6. 在页中根据页目录查询记录步骤
                1. 通过二分法确定该记录所在的槽，并找到该槽所在分组中主键值最小的那条记录
                2. 通过记录的next_record属性遍历该槽所在的组中的各个记录。
    5. InnoDB 存储引擎是面向行的,也就是说数据是按行进行存放的，每个页存放的行记录也是有硬性定义的，最多允许存放7992 行记录
        * 行结构
            1. 额外信息
                1. 变长字段,如varchar(M),字段长度不固定,这里存放变长字端真实长度,按照列的【顺序】逆序存放,且当字符集为非边长字符集  
                如ascii时,char(M)长度才不会放入边长字段中
                2. NULL值列表，每一个允许为空得列对应一个二进制位,二进制位按照顺序的逆序排列
                3. 记录头信息，固定5个字节,也就是40个二进制位,包含许多基本属性
                    * 名字     大小(bit)   描述
                    * 预留位1	    1	没有使用
                    * 预留位2	    1	没有使用
                    * delete_mask	1	标记该记录是否被删除
                    * min_rec_mask	1	B+树的每层非叶子节点中的最小记录都会添加该标记
                    * n_owned	    4	表示当前记录拥有的记录数
                    * heap_no	    13	表示当前记录在记录堆的位置信息
                    * record_type	3	表示当前记录的类型，0表示普通记录，1表示B+树非叶节点记录，2表示最小记录，3表示最大记录
                    * next_record	16	表示下一条记录的相对位置,排序是按照主键由小到大,指向下一行记录真实信息和额外的信息中间,  
                    因为记录信息中null值列表和边长字段都是倒序,从右往左查询刚好为正,二分思想
            2. 真实信息
                1. 隐藏列,如row_id(唯一标识记录,非必须),transaction_id(事务Id),roll_pointer(回滚指针)
                    * trx_id：每次一个事务对某条聚簇索引记录进行改动时(真正修改记录时)，都会把该事务的事务id赋值给trx_id隐藏列
                    * roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当  
                    于一个指针，可以通过它来找到该记录修改前的信息
                2. 列存储的真实值,当真实值数据过大,会发生行溢出,超过页的承受范围,真实值会分布到其他几页,该真实值位置则放指向页的指针
       * Dynamic是5.7默认行格式,与上述的Compact很相似,最大区别在于行溢出时,Compact在列中存放一部分实际数据然后外加其他页地址,Dynamic则
       * 一条行记录被删除并不会马上被从硬盘上删除,而是会把next_record写为0,放入垃圾链表,之后如果有新记录插入到表中的话，可能把这些被删除  
       的记录占用的存储空间覆盖掉。  
       完全只存放其他页地址,不存真实数据     
5. 事务
    1. 事务隔离级别
        * 未提交读: 一个事务读取到其他事务未提交的数据，是级别最低的隔离机制；
        * 提交读: 一个事务读取到其他事务提交后的数据
        * 可重复读: 一个事务对同一份数据读取到的相同，不在乎其他事务对数据的修改；
        * 序列化: 事务串行化执行，隔离级别最高，牺牲了系统的并发性
    2. 事务的并发会造成的问题
       * 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
       * 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次  
       读取同一数据时，结果 不一致    
       * 幻读：同一事务中对同一范围的数据进行读取，结果却多出了数据或者少了数据，这就叫幻读
    3. ACID
        1. 原子性 操作是一个不可分割的操作
        2. 隔离性 要保证其它的状态转换不会影响到本次状态转换
        3. 一致性 最终结果保存相等
        4. 持久性 当执行一个操作后，这个转换的结果将永久的保留
    4. 事务开启有三种模式
        * READ ONLY：标识当前事务是一个只读事务，也就是属于该事务的数据库操作只能读取数据，而不能修改数据
        * READ WRITE：标识当前事务是一个读写事务，也就是属于该事务的数据库操作既可以读取数据，也可以修改数据(默认)
        * WITH CONSISTENT SNAPSHOT：启动一致性读
        * 在只读事务中不可以对普通的表（其他事务也能访问到的表）进行增、删、改操作，但可以对临时表做增、删、改操作
    5. 保存点;是在事务对应的数据库语句中打几个点，我们在调用ROLLBACK语句时可以指定会滚到哪个点，而不是回到最初的原点
    6. 这个事务id本质上就是一个数字，它的分配策略和我们前边提到的对隐藏列row_id(id值)的分配策略大抵相同
         * 服务器会在内存中维护一个全局变量，分配一个事务id时，就会把该变量的值当作事务id分配给该事务，并且把该变量自增1
         * 每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的页号为5的页面中一个称之为Max Trx ID的属性处
         * 当系统下一次重新启动时，会将上边提到的Max Trx ID属性加载到内存中，将该值加上256之后赋值给我们前边提到的全局变量  
         ,因为上次分配出去的值不可能大于256
    7. ReadView(MVCC)
        1. 原理:当多个事务对一行数据修改时,roll_pointer会存储所有的更新信息,按照事务id从大到小排序。其他事务中若读取该事务  
        按照判断规则获取对应的一行数据返回
        2. 构成
            1. m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。
            2. min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。
            3. max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。
            4. creator_trx_id：表示生成该ReadView的事务的事务id。
        3. 判断
            1. 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问
            2. 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问
            3. 如果被访问版本的trx_id属性值大于或等于ReadView中的max_trx_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问
            4. 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中  
            如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。
            5. 如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。  
            如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录
    8.事务级别
        * READ UNCOMMITTED,直接读取 记录的最新版本就好
        * READ COMMITTED 在每次查询开始时都会生成一个独立的ReadView。
        * REPEATABLE READ 在第一次读取数据时生成一个ReadView,所以事务中每次读取的ReadView相同,得到的行数据下roll_pointer相同
        * SERIALIZABLE(串行化)在第一个事务更新了某条记录后，就会给这条记录加锁，另一个事务再次更新时就需要等待第一个事务提交了，把锁释放之后才可以继续更新
    
6. 服务器处理客户端请求过程 处理连接->查询缓存->语法解析->查询优化->存储引擎
    * 连接管理/连接器:连接器就是用来客户端和服务器进程之间建立连接的,这个方式有很多,比如说TCP/IP,命名管道或共享内存等等,这个阶段的连接需要客户端提供主机信息,用户名以及密码,  
    服务器会对提供的信息进行认证,不仅仅是账户密码的匹配,还有权限的验证
    * 查询缓存:这个的意思的Mysql服务器程序处理请求,会把刚刚请求过的查询请求和结果缓存起来,,下一次有一模一样的请求过来,直接从缓存中查找结果会更快.参考3.1
    * 语法解析:包括了词法分析,语法分析,语义分析等. 词法分析会分析出这条sql语句的关键词,表名和列名等等.语法分析则会分析这条sql语句是否有错误,比如关键字select是否正确等
    * 查询优化:mysql会对我们写的sql语句进行一些优化,如外连接转换为内连接、表达式简化、子查询转为连接等,优化的结果就是生成一个执行计划,这个计划表名该sql语句会使用什么索引进行查询
    * 执行:在真正开始执行前会判断当前用户是否有操作的权限,有的话会根据操作表的结构去存储引擎操作
7. 字符编码解析过程
    1. 客户端使用操作系统的字符集编码发送字符串到mysql
    2. mysql根据配置character_set_client节码,转成character_set_connection(理解为mysql字符集)字符集  
    3. 执行sql一系列操作将返回结果转为character_set_results对应的字符集
    4. 操作系统接受到结果，转为自身的字符集
8. 索引
    1. 聚簇索引
        * 索引数据与主键一致按顺序排列分布在不同的页中,且页数不连续,由指针构成链表
        * 索引由专门的索引页构成，其中设置行的头信息record_type=1,存放页的用户记录中最小的主键值,页号
        * 在加一个索引页存放2设置的索引页,加快找到对应的数据索引页,这样形式上构成了一颗B+树
        * B+树的叶子节点存储的是完整的用户记录。
        * 聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建.InnoDB存储引擎会自动的为我们创建聚簇索引
    2. 二级索引
        * 根据设置的非主键建立的索引字段创建一个新的B+树
        * 中间一层目录节点与聚簇索引不同,存储为三个部分索引列的值,(主键值),页号,这样就保证主键值+页号唯一性,避免了索引列的值  
        相同情况,新的相同索引列插入时不知道插入那张页的问题
        * B+树的叶子节点存储的并不是完整的用户记录，而只是索引列+主键这两个列的值
        * 所以根据二级索引需要先在该索引中查询出主键,再通过主键查询聚簇索引查询到值,这一步操作也叫回表
    3. 联合索引
        * 多个字段建立的索引为联合索引，本质上也是一个二级索引
        * 排序顺序按字段顺序来,如C1,C2两字段为组合索引,按C1排序,若C1相同则再按C2来
    4. 一个B+树索引的根节点自诞生之日起，便不会再移动
    5. InnoDB和MyISAM会自动为主键或者声明为UNIQUE的列去自动建立B+树索引    
    6.索引原则
        * 联合索引第二点说明了在联合索引中的最左匹配原则
        * 索引排序字符串比较大小是先按一位位字符从前往后比较,所以前缀都是排好序的,所以可以得到like查询时,只支持后面模糊查询走索引
        * 范围查询时,因为索引字段是排序的,所以支持索引的,但是联合时,只有最左有完整的链路,所以只支持最左范围查询。同理,当最左  
        的查询时精确查询(=)时,第二个索引字段可以范围查询
        * order by 若是索引字段则也减去了排序时间,当然若是联合索引也必须按照索引顺序order by
        * 当批量查询数据时,第一次查询二级索引,很快速可以查询出需要的页于其对应的主键集合,这是顺序I/O,但是根据主键查询聚簇索引  
        查询对应行数据时,因为主键地址不是连续的,所以是随机I/O,当集合非常大时,效率很低,这就是回表的代价,这时候不如采用全表查询
        * 如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的
        * 对应主键索引来说,非顺序性会进行行链表的断开再插入,顺序只会插入,所以让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们0手动插入
9. 执行计划
    * 级别,从快到慢
        1. const(常量级别) 根据聚簇索引或者二级索引(唯一)=号查询,直接找到地址
        2. ref根据二级索引=号查询,因为二级索引不具有唯一性,有可能有多个key(二级索引字段)->主键id,所以会查出多条
        3. ref_or_null有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来
        4. range查询符号为=、<=>、IN、NOT IN、IS NULL、IS NOT NULL、>、<、>=、<=、BETWEEN、!=或者LIKE操作符连接起来
        5. index 查询列为联合索引的索引列,且搜索条件也是联合索引的列,可以通过遍历联合索引的列来匹配条件
        6. all 全表
    * 当多个二级索引进行查询时,会根据表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少,从而根据该条件查询二级  
    索引,然后回表(根据结果查询聚簇索引) 得到的数据进行后续的判断  
    * Intersection交集索引可以在某个查询使用多个二级索引，将从多个二级索引中查询到的结果取交集(AND)
        1. 二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况
        2. 主键列可以是范围匹配(因为二级索引的用户记录是由索引列 + 主键构成的，二级索引列的值相同的记录可能会有好多条，这些索引列  
        的值相同的记录又是按照主键的值进行排序的)
    * Union并集索引(Intersection和Union本质上都是合并一部分查询结果)
        1. 二级索引列是等值匹配的情况
        2. 主键列可以是范围匹配
        3. 使用Intersection索引合并的搜索条件
    * Sort-Union合并,当两个二级索引为区间查询时且关联条件为or.这种情况会把两个区间条件根据条件查出再按主键排序,然后再合并,比  
    Union多了一步排序
    * 当多表连接时,根据条件选择一张表进行查询,这张表称为驱动表,然后根据驱动表的结果每条记录去多张表生成的笛卡尔积中删选出  
    结果再次进行根据条件查询,访问次数取决于对驱动表执行单表查询后的结果集中的记录条数    
    * 内连接和外连接的根本区别就是在驱动表中的记录不符合ON子句中的连接条件时不会把该记录加入到最后的结果集
    * 基于块的嵌套循环连接。提前划出一块内存（join buffer）存储驱动表结果集中的记录，然后开始扫描被驱动表，每一条被驱动表的  
    记录一次性和这块内存中的多条驱动表记录匹配，可以显著减少被驱动表的I/O操作
10. 规则优化
    1. 条件简化,如移除不必要的括号,常量传递,等值传递,移除没用的条件,表达式计算,HAVING子句和WHERE子句的合并
    2. 外连接消除:在被驱动表的WHERE子句符合空值拒绝的条件后，外连接和内连接可以相互转换,这种转换带来的好处就是查询优化器  
    可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序来执行查询
    3. 对于子查询,若子查询和父亲无关连,先执行只查询再跟据结果集查询父亲,若父子有连,先查询父亲中的结果,循环出结果集每一条数据  
    将关联字段带入子查询,若满足则加入最终结果集
    4. 对于In查询,当里面特别多时不直接将不相关子查询的结果集当作外层查询的参数，而是将该结果集写入一个临时表里
11. 日志
    * redo日志
        1. 因为缓存区不会立即将数据提交,当系统断电,放入缓存的地方是内存,所以断电会不见,为了持久化,所以引出redo日志
        2. redo日志会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统崩溃重启后可以把事务所做的任何修改都恢复出来
    * undo日志
        1. 回滚的本质就是把回滚时所需的东西都给记下来,称为撤销日志undo log
            * 你插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了
            * 你删除了一条记录，至少要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了
            * 你修改了一条记录，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了
        2. insert undo在事务提交之后就可以被释放掉了，而update undo由于还需要支持MVCC，不能立即删除掉
        3. 为了支持MVCC，对于delete mark操作来说，仅仅是在记录上打一个删除标记，并没有真正将它删除掉
12. 锁
    1. S(共享锁,行级别),IS(意向共享锁,极一条数据要获取行锁时现在表上加一条带我我要获取X锁的表锁),X,IX(排他锁,意向排他锁)
    2. 对表结果修改时,会导致语句阻塞,同理,事务执行时会对表修改阻塞.DDL语句执行时会隐式的提交当前会话中的事务
    3. 为了解决幻读,提出gap锁,当给聚簇索引某行加上他后,他与前面一行不允许进行插入的,可以在尾节点record_type=3的节点加入GapLock,  
    保证该页不会有数据在数据节点后再插入,同样在内存会有存储意向插入GapLock
13. 优化
    1. select * 和 select 全部字段的 2 种写法有何优缺点
        - 前者要解析数据字典，后者不需要
        - 结果输出顺序，前者与建表列顺序相同，后者按指定字段顺序
        - 表字段改名，前者不需要修改，后者需要改
        - 后者可以建立索引进行优化，前者无法优化
        - 后者的可读性比前者要高
    2. 避免使用 NULL，NULL 需要特殊处理, 大多数时候应该使用 NOT NULL，或者使用一个特殊的值
    3. 仅可能使用更小的字段，MySQL 从磁盘读取数据后是存储到内存中的，然后使用 cpu 周期和磁盘 I/O 读取它，这意味着越小的  
    数据类型占用的空间越小
    4. 客户端或应用程序使用的字符集可能和表本身的字符集不一样，这需要MySQL 在运行过程中隐含地进行转换，此外，要确定字符  
    集如 UTF8 是否支持多字节字符，因此它们需要更多的存储空间
    5. 尽量将子查询改为连接查询,因为MySQL 查询优化引擎并不是总是最有效的
    6. 深分页解决 SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
14. 三大范式
    1. 要求数据库表的每一列都是不可分割的原子数据项。
    2. 需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）
    3. 需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关

### Spring源码部分       
1. @Import 可以传入四种类型：普通类、配置类、ImportSelector 的实现类,ImportBeanDefinitionRegistrar的实现类
2. 自动装配
    * @SpringBootApplication->@EnableAutoConfiguration->@AutoConfigurationPackage->@Import(AutoConfigurationPackages.Registrar.class)
    * AutoConfigurationPackages.Registrar中取主启动类所在包及子包下的组件设置为basePackage.
    * @SpringBootApplication-》@EnableAutoConfiguration-》@Import(EnableAutoConfigurationImportSelector.class)
    * AutoConfigurationImportSelector:读取META-INF/spring.factories(spring-boot-autoconfigure)下所有的自动配置类装配到IOC容器中，之后自动配置类就会  
    通过 ImportSelector 和 @Import 的机制被创建出来，之后就生效了
3. SPI是一种动态替换发现的机制,在META-INF/services里面声明接口的全类名,通过ServiceLoader加载出实现它的子类
4. MVC
    * 自动配置类
        - @WebMvcAutoConfiguration为springMvc的配置类(spring-boot-autoconfigure下META-INF/spring.factories里包含)
        - 代码
             ``` 
                        @Configuration
                        //当前环境必须是WebMvc（Servlet）环境
                        @ConditionalOnWebApplication(type = Type.SERVLET)
                        //当前运行环境的classpath中必须有Servlet类，DispatcherServlet类，WebMvcConfigurer类
                        @ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })
                        //如果没有自定义WebMvc的配置类，则使用本自动配置
                        @ConditionalOnMissingBean(WebMvcConfigurationSupport.class)
                        @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)
             *           // @AutoConfigureAfter表示该类需要在DispatcherServletAutoConfiguration实例化后执行
                        @AutoConfigureAfter({ DispatcherServletAutoConfiguration.class,
                        		TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class })
                        public class WebMvcAutoConfiguration {
             ```
        - WebMvcAutoConfiguration->DispatcherServletAutoConfiguration->ServletWebServerFactoryAutoConfiguration
            1. ServletWebServerFactoryAutoConfiguration下通过@Import导入ServletWebServerFactoryConfiguration.EmbeddedTomcat.class
                ``` 
                    @Configuration
                    //@ConditionalOnClass表示当前classPath下必须有Tomcat 这个类，该配置类才会生效
               	*     @ConditionalOnClass({ Servlet.class, Tomcat.class, UpgradeProtocol.class })
               	    @ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT)
               	    public static class EmbeddedTomcat {
                
               	    	@Bean
               	    	public TomcatServletWebServerFactory tomcatServletWebServerFactory() {
               	    	//初始化Tomcat
               	    		return new TomcatServletWebServerFactory();
               	    	}
                
               	    }
                ```
            2. DispatcherServletAutoConfiguration分别注册 DispatcherServlet和DispatcherServletRegistrationBean
            3. WebMvcAutoConfiguration注册了国际化组件,视图解析器,静态资源映射,主页的设置,应用图标的设置等等
            4. WebMvcAutoConfiguration注册了国际化组件注册了SpringWebMvc 中最核心的两个组件：处理器适配器、处理器映射器。
            5. 里面大部分使用了内部静态类，为了不向外暴露这个内部类而已；毕竟只是在外部类配置场景需要用到
    * 外部war启动流程
        - 在Servlet容器（Tomcat、Jetty等）启动应用时，会扫描应用jar包中 ServletContainerInitializer 的实现类。  
         框架必须在jar包的 META-INF/services 的文件夹中提供一个名为 javax.servlet.ServletContainerInitializer 的文件，    
         文件内容要写明 ServletContainerInitializer 的实现类的全限定名(Servlet3.0规范中引导应用启动的说明)
        - 基于此SpringServletContainerInitializer实现了ServletContainerInitializer
        - 在SpringServletContainerInitializer上有注解@HandlesTypes(WebApplicationInitializer.class),该注解会将其里面  
        WebApplicationInitializer所有普通实现类都实例化出来，之后分别调他们自己的 onStartup 方法
        - SpringBootServletInitializer为WebApplicationInitializer得实现类,也调用其onStartup方法
        - SpringBootServletInitializer#onStartup下核心createRootApplicationContext方法里面创建SpringApplication并且run
    *  @Controller标注的Bean装配MVC原理
        - WebMvcAutoConfiguration中注册了RequestMappingHandlerMapping,其中有afterPropertiesSet方法
        - 其调用父类,判断是否含有Controller或RequestMapping,然后将@RequestMapping封装成一个RequestMappingInfo
        - RequestMappingInfo会先解析方法级别RequestMapping,再解析类级别,加上路径前缀进行拼接
        - 开启一个写锁保证线程安全封装 Controller 和它的方法，变成一个 HandlerMethod 对象，之后分别保存三组Map映射,完成注册。
        - 映射分别为
            1. RequestMappingInfo:Controller,
            2. 注解中的映射url:和RequestMappingInfo
            3. Controller目标方法:跨域配置
        - 至此，@Controller 中的 @RequestMapping 信息已经被装载进 RequestMappingHandlerMapping 中
    * DispatcherServlet的工作原理
        * 工作流程
            - 浏览器向服务器发起请求，由 DispatcherServlet 接收请求
            - DispatcherServlet 委托 HandlerMapping，根据 url 来选择一个合适的 Controller 中的方法
            - HandlerMapping 找到合适的 Controller 后，并根据已配置的拦截器，整理出一个 Handler，返回给 DispatcherServlet
            - DispatcherServlet 收到 Handler 后委托 HandlerAdapter，将该请求代理给 HandlerMapping 选定的 Controller 中的 Handler
            - Handler 收到请求后，实际执行 Controller 中的方法，执行完毕后会返回 ModelAndView
            - Controller 方法执行完毕后会返回 ModelAndView
            - HandlerAdapter 收到 Handler 返回的 ModelAndView 后返回给 DispatcherServlet
            - DispatcherServlet 拿到 ModelAndView 后委托 ViewResolver，由 ViewResolver 负责渲染视图
            - ViewResolver 渲染视图完成后，返回给 DispatcherServlet，由 DispatcherServlet 负责响应视图 
        * 代码流
            - 进入DispatcherServlet父类HttpServlet的service方法,然后根据请求类型分发到FrameworkServlet的processRequest方法上
            - 将当前线程数据取出传入新封装好的请求参数和上下文,目的是目的是线程隔离
            - 将IOC容器及特定组件放入request供开发使用,然后缓存一个SessionFlashMapManager,用来保存页面参数缓存
            - 校验并解析上传的文件,然后根据URL从拿到对应的对应HandlerMethod,其中读取时采用读锁,与上面写锁对应
            - 获取HandlerMethod进行拦截器处理,来判断是否能够匹配当前请求URL
            - 然后获取所有适配器来判断那个适配器能处理HandlerMethod返回HandlerAdapter
            - 执行拦截器(springMVC拦截器功能就在此实现:HandlerInterceptorAdapter,WebMvcConfigurerAdapter),如果拦截器返回true，代表继续向后执行剩余的拦截器；如果返回false，  
            代表拦截器将该方法拦截，不执行后续的拦截器和 Controller 中的方法。
            - 正式执行HandlerAdapter.handle准备执行逻辑处理
            - 初始化Controller中一个WebDataBinder,来对这个控制器中的数据绑定器做定制修改。通常情况下我们不会操作WebDataBinder,
            WebDataBinder它的作用就是从webrequest里绑定到JavaBean上
            - 寻找不带 @RequestMapping 但带 @ModelAttribute 的方法(进入 Controller 的指定方法之前，标有 @ModelAttribute 注解的方法会先执行)
            - HandlerMethod 封装为 ServletInvocableHandlerMethod,执行其下invokeAndHandle(实际调用Controller)方法
            - invokeAndHandle中首先获得方法的所有参数类型,进行判断是否能够转化,能够就保存下来方便后面获取，不行就报错
            - 然后获取方法参数所有的key,再根据key通过调用原生Api操作获得值,然后再进行转化
            - 然后反射调用Controller 里的方法。得到的结果寻找一个ReturnValueHandler匹配一个最合适的适配器,页面采用ViewNameMethodReturnValueHandler
            - 再然后包装一个根据已有信息包装一个ModelAndView 返回
            - 返回后来判断 header 中是否有 "Cache-Control" 来决定最后的跳转(默认不带,从而只设置一些缓存信息)
            - 然后回调拦截器(HandlerInterceptorAdapter)的postHandle方法
            - 然后根据ModelAndView判断是否有异常,如果有异常寻找合适的异常处理器返回,若没有则渲染视图
            - 最后回调拦截器(HandlerInterceptorAdapter)的afterConcurrentHandlingStarted方法
        * @ResponseBody响应json数据的原理:在对Controller结果进行处理时,不采用ViewNameMethodReturnValueHandler，而是使用 RequestResponseBodyMethodProcessor
    * 9大组件
        - 通过onRefresh方法初始化,初始了9个组件
        - HandlerMapping:根据request找到相应的处理器Handler和Intecepter拦截器
        - HandlerAdapter:handle方法就是使用handler来处理逻辑的。处理之后返回一个ModelAndView
        - HandlerExceptionResolver:这个组件的作用就是根据异常设置ModelAndView，然后再将处理结果交给render方法进行渲染。
        - ViewResolver:ViewResolver的作用是将String类型的逻辑视图根据local解析为View视图
        - LocalResolver:解析视图需要两个参数，一个是String类型的逻辑视图名，另外一个是local。LocalResolver的作用就是从  
        request中解析出local的(viewName String类型的视图名,local 区域，可以用来做国际化)
        - ThemeResolver:对于我们常见的网页界面活着手机界面来说，一套主题无非就是换一套图片，活着css样式文件等等。  
        我们通过ThemeResolver这个就可以实现这样的功能
        - RequestToViewNameTranslator:将request请求转换为视图名称
        - MultipartResolver:MultipartResolver就是用来处理上传请求的。其处理方式就是将request包装成MultipartHttpServletRequest
        - FlashMapManager:这个在redirect是进行参数传递需要用到
5. 启动流程
    1. 创建SpringApplication
        ``` 
            @SuppressWarnings({ "unchecked", "rawtypes" })
            public SpringApplication(ResourceLoader resourceLoader, Class<?>... primarySources) {
                // resourceLoader为null
                this.resourceLoader = resourceLoader;
                Assert.notNull(primarySources, "PrimarySources must not be null");
                // 将传入的DemoApplication启动类放入primarySources中，这样应用就知道主启动类在哪里，叫什么了
                // SpringBoot一般称呼这种主启动类叫primarySource（主配置资源来源）
                this.primarySources = new LinkedHashSet<>(Arrays.asList(primarySources));
                // 3.1 判断当前应用环境
                this.webApplicationType = WebApplicationType.deduceFromClasspath();
                // 3.2 设置初始化器
                setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));
                // 3.3 设置监听器
                setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
                // 3.4 确定主配置类
                this.mainApplicationClass = deduceMainApplicationClass();
            }
        ```
        * (3.1)WebApplicationType.deduceFromClasspath()来决定是什么环境，本质上扫描是否有Reactiv的包,是否  
          有Servlet相关的类,若都没有就是个普通应用
        * (3.2)Initializers用于在刷新容器之前初始化Spring ConfigurableApplicationContext 的回调接口
        * (3.2)三种实现方式:实现ApplicationContextInitializer,application.properties中配置,spring.factories中配置   
        * (3.3)ApplicationListener由应用程序事件监听器实现的接口。基于观察者模式的标准 java.util.EventListener 接口。
        * (3.4)从deduceMainApplicationClass 方法开始往上爬，哪一层调用栈上有main方法，方法对应的类就是主配置类，就返回这个类
    2. run方法
        ``` 
        public ConfigurableApplicationContext run(String... args) {
            // 4.1 创建StopWatch对象
            StopWatch stopWatch = new StopWatch();
            stopWatch.start();
            // 4.2 创建空的IOC容器，和一组异常报告器
            ConfigurableApplicationContext context = null;
            Collection<SpringBootExceptionReporter> exceptionReporters = new ArrayList<>();
            // 4.3 即使没有检测到显示器,也允许其启动.对于服务器来说,是不需要显示器的,所以要这样设置
            configureHeadlessProperty();
            // 4.4 获取SpringApplicationRunListeners，并调用starting方法（回调机制）
            SpringApplicationRunListeners listeners = getRunListeners(args);
            // 【回调】首次启动run方法时立即调用。可用于非常早期的初始化（准备运行时环境之前）。
            listeners.starting();
            try {
                // 将main方法的args参数封装到一个对象中
                ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
                // 4.5 准备运行时环境
                ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);
               // 4.6 如果有配置 spring.beaninfo.ignore，则将该配置设置进系统参数
               configureIgnoreBeanInfo(environment);
               // 4.7 打印SpringBoot的banner
               Banner printedBanner = printBanner(environment);
               // 4.8 创建ApplicationContext
               context = createApplicationContext();
               // 初始化异常报告器
               exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,
                       new Class[] { ConfigurableApplicationContext.class }, context);
               // 4.9 初始化IOC容器
               prepareContext(context, environment, listeners, applicationArguments, printedBanner);
               // 4.10 bean的生命流程,刷新容器,最重要
               refreshContext(context);
              // 4.11 刷新后的处理
               afterRefresh(context, applicationArguments);
               stopWatch.stop();
               if (this.logStartupInfo) {
                   new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);
               }
               // 4.12 发布started事件
               listeners.started(context);
               // 4.13 运行器回调
               callRunners(context, applicationArguments);
            }
        ```
        * (4.1)new 一个StopWatch用于统计run启动过程花了多少时间
        * (4.4)SpringApplicationRunListeners是监听SpringApplication运行方法。 
        * (4.5)Environment它是IOC容器的运行环境，它包括Profile和Properties两大部分，它可由一个到几个激活的Profile共同配置，  
        它的配置可在应用级Bean中获取 
        * (4.5)意义为准备环境变量，包括系统变量，环境变量，命令行参数，默认变量，servlet相关配置变量，随机值JNDI属性值，  
        以及配置文件（比如application.properties）等，注意这些环境变量是有优先级的 
        * (4.8)里面根据运行环境创建ApplicationContext,在实例化时先初始化父类构造方法创建(this.beanFactory = new DefaultListableBeanFactory();)
        * (4.9)IOC容器初始化工作
            - 将创建好的应用环境设置到IOC容器中
            - 将beanName生成器,资源加载器,类加载器,类转化器放入IOC
            - 会获取到所有 Initializer，调用initialize方法
            - 生成一个bean加载器(就是注解驱动的Bean定义解析器,Xml定义的Bean定义解析器类路径下的Bean定义扫描器的整合)
            - 进入load()方法,循环所有的sources(仅主启动类一个),根据类型判断(判断为类),再判断是否含有注解Component,最后annotatedReader.register
            - 到这一步,就将主启动类生成为BeanDefinition 放入了IOC容器中
        * (4.10)刷新容器
            ``` 
                public void refresh() throws BeansException, IllegalStateException {
                    synchronized (this.startupShutdownMonitor) {
                        // Prepare this context for refreshing.
                        // 1. 初始化前的预处理
                        prepareRefresh();
                
                        // Tell the subclass to refresh the internal bean factory.
                        // 2. 获取BeanFactory，加载所有bean的定义信息（未实例化）
                        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
                
                        // Prepare the bean factory for use in this context.
                        // 3. BeanFactory的预处理配置
                        prepareBeanFactory(beanFactory);
                
                        try {
                            // Allows post-processing of the bean factory in context subclasses.
                            // 4. 准备BeanFactory完成后进行的后置处理
                            postProcessBeanFactory(beanFactory);
                
                            // Invoke factory processors registered as beans in the context.
                            // 5. 执行BeanFactory创建后的后置处理器
                            invokeBeanFactoryPostProcessors(beanFactory);
                
                            // Register bean processors that intercept bean creation.
                            // 6. 注册Bean的后置处理器
                            registerBeanPostProcessors(beanFactory);
                
                            // Initialize message source for this context.
                            // 7. 初始化MessageSource（SpringMVC）
                            initMessageSource();
                
                            // Initialize event multicaster for this context.
                            // 8. 初始化事件派发器
                            initApplicationEventMulticaster();
                
                            // Initialize other special beans in specific context subclasses.
                            // 9. 子类的多态onRefresh
                            //SpringBoot 扩展的IOC容器中对这个方法进行了真正地实现
                            onRefresh();
                
                            // Check for listener beans and register them.
                            // 10. 注册监听器
                            registerListeners();
                          
                            //到此为止，BeanFactory已创建完成
                
                            // Instantiate all remaining (non-lazy-init) singletons.
                            // 11. 初始化所有剩下的单例Bean
                            finishBeanFactoryInitialization(beanFactory);
                
                            // Last step: publish corresponding event.
                            // 12. 完成容器的创建工作
                            finishRefresh();
                        }
                
                        catch (BeansException ex) {
                            if (logger.isWarnEnabled()) {
                                logger.warn("Exception encountered during context initialization - " +
                                        "cancelling refresh attempt: " + ex);
                            }
                
                            // Destroy already created singletons to avoid dangling resources.
                            destroyBeans();
                
                            // Reset 'active' flag.
                            cancelRefresh(ex);
                
                            // Propagate exception to caller.
                            throw ex;
                        }
                
                        finally {
                            // Reset common introspection caches in Spring's core, since we
                            // might not ever need metadata for singleton beans anymore...
                            // 13. 清除缓存
                            resetCommonCaches();
                        }
                    }
                }
            ``` 
            * (1)其中initPropertySources()虽然为空方法,但是在servlet环境下有实现,会把web.xml等信息放入IOC
            * (3)BeanPostProcessor它通常被称为 “Bean的后置处理器“它可以在对象实例化但初始化之前，以及初始化之后进行一些后置处理
            * (4)org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext#postProcessBeanFactory为实现类
            * (4)把ServletContext,ServletConfig注入到组件中,且将Web的几种作用域注册到 BeanFactory 中。
            * (5)执行beanFactory的后置处理器,里面进行了包扫描等等操作
            * (5)注意执行的org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry,会加载出所有类信息
            * (9)实现类在SpringBoot org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext#onRefresh
            * (9)在这里创建了Tomcat
            * (12)ServletWebServerApplicationContext 还重写了 finishRefresh 方法,调用了 WebServer 的start方法真正启动嵌入式Web容器
            
6. IOC小结
    * 执行顺序 构造方法->BeanPostProcessor的before方法->@PostConstruct/init-method->InitializingBean的afterPropertiesSet方法->BeanPostProcessor的after方法 
    * BeanFactoryPostProcessor是在所有的 BeanDefinition 已经被加载，但没有Bean被实例化,可以对 BeanFactory 进行后置处理。BeanDefinitionRegistryPostProcessor  
    它的执行时机是所有Bean的定义信息即将被加载但未实例化时，也就是先于 BeanFactoryPostProcessor;总结就是【规律】BeanPostProcessor 是对Bean的后置处理，BeanFactoryPostProcessor   
    是对 BeanFactory 的后置处理
    * spring会把classPath下所有class文件解析出来,然后使用类加载器，把传入的根包以Resource的形式加载出来,然后通过一个MetadataReader来解析.class文件，  
    它就可以读取这个class的类定义信息、注解标注信息。之后要用 MetadataReader 来判断这个class是否为一个 Component,判定为 Component 后，  
    会将这个class封装为 BeanDefinition，最后返回
    * org.springframework.context.annotation.AnnotationBeanNameGenerator为注解的bean名称生成器,规则为看这些模式注解上是否有  
    显式的声明 value 属性，如果没有则进入下面的 buildDefaultBeanName 方法，它会取类名的全称，之后调 Introspector.decapitalize 方法将首字母转为小写
    * SpringBoot 会根据classpath下存在的类，决定当前应用的类型，以此来创建合适的IOC容器。默认WebMvc环境下，创建的IOC容器是 AnnotationConfigServletWebServerApplicationContext
    * SpringBoot 使用 SpringFactoriesLoader.loadFactoryNames 机制来从 META-INF/spring.factories 文件中读取指定 类/注解 映射的组件全限定类名，  
    以此来反射创建组件。Spring设计的SPI比Java原生的SPI要更灵活，因为它的key可以任意定义类/注解，不再局限于“接口-实现类”的形式
    * SpringApplicationRunListener 可以监听 SpringApplication 的运行方法。通过注册 SpringApplicationRunListener ，  
    可以自定义的在 SpringBoot 应用启动过程、运行、销毁时监听对应的事件，来执行自定义逻辑
    * Spring应用的IOC容器需要依赖 Environment - 运行环境，它用来表示整个Spring应用运行时的环境，它分为 profiles 和 properties 两个部分。  
    通过配置不同的 profile ，可以支持配置的灵活切换，并且可以同时配置一到多个 profile 来共同配置 Environment
    * 后置处理器
            * BeanPostProcessor(接口)：Bean实例化后，初始化的前后触发
                1. AutowiredAnnotationBeanPostProcessor：负责处理 @Autowired 、@Value 等注解
                2. InstantiationAwareBeanPostProcessor：Bean的实例化对象的前后过程、以及实例的属性设置（AOP）
                3. InitDestroyAnnotationBeanPostProcessor：触发执行Bean中标注 @PostConstruct 、@PreDestroy 注解的方法
            * BeanFactoryPostProcessor(接口)：所有的 BeanDefinition 已经被加载，但没有Bean被实例化时触发    
                1. ConfigurationClassPostProcessor：解析加了 @Configuration 的配置类，解析 @ComponentScan 注解扫描的包，以及解析 @Import 、@ImportResource 等注解
            * BeanDefinitionRegistryPostProcessor(继承BeanFactoryPostProcessor,提供不同的方法)：所有Bean的定义信息即将被加载但未实例化时触发   
    * Dubbo 会在 Spring 实例例化完 bean 之后，在刷新容器器最后⼀一步发布 ContextRefreshEvent 事件的时候，通知实现了了  
    ApplicationListener 的 ServiceBean 类进⾏行行回调 onApplicationEvent 事件⽅方法，Dubbo 会在这个⽅方法中调⽤用 ServiceBean   
    ⽗父类ServiceConfig 的 export ⽅方法，⽽而该⽅方法真正实现了了服务的（异步或者⾮非异步）发布    
7. 循环依赖
    * 重要集合
        - singletonObjects：一级缓存，存放完全初始化好的Bean的集合，从这个集合中取出来的Bean可以立马返回
        - earlySingletonObjects：二级缓存，存放创建好但没有初始化属性的Bean的集合，它用来解决循环依赖
        - singletonFactories：三级缓存，存放单实例Bean工厂的集合
        - singletonsCurrentlyInCreation：存放正在被创建的Bean的集合                
    * 思路
        - 初始化 Bean 之前，将这个 bean 的 name 放入三级缓存
        - 创建 Bean 将准备创建的 Bean 放入 singletonsCurrentlyInCreation （正在创建的 Bean ）
        - createNewInstance 方法执行完后执行 addSingletonFactory，将这个实例化但没有属性赋值的 Bean 放入三级缓存，
        并从二级缓存中移除,一般情况下初次创建的 bean 不会存在于二级缓存，故该步骤可以简单理解为仅仅是放入了三级缓存而已
        - 属性赋值&自动注入时，引发关联创建
        - 关联创建时判断
            1. 检查“正在被创建的 Bean ”中是否有即将注入的 Bean
            2. 如果有，检查二级缓存中是否有当前创建好但没有赋值初始化的 Bean
            3. 如果没有，检查三级缓存中是否有正在创建中的 Bean
            4. 至此一般会有，将这个 Bean 放入二级缓存，并从三级缓存中移除
        - 之后 Bean 被成功注入，最后执行 addSingleton，将这个完全创建好的Bean放入一级缓存，从二级缓存和三级缓存移除，
        并记录已经创建了的单实例Bean    
8. AOP
    * 通过@EnableAspectJAutoProxy中@Import(AspectJAutoProxyRegistrar.class)创建出AnnotationAwareAspectJAutoProxyCreator
    * AnnotationAwareAspectJAutoProxyCreator扩展了InstantiationAwareBeanPostProcessor接口,而其可以做组件的 创建前后、初始化前后的后置处理工作
    * createBean第一次执行后置处理器AbstractAutoProxyCreator(AspectJAwareAdvisorAutoProxyCreator)
    * 后置处理器里面本质上是创建动态代理的配置类,默认单例返回为空.里面就仅仅根据@aspect生成代理增强器放入IOC
    * 进入doCreateBean->initializeBean ->applyBeanPostProcessorsAfterInitialization 又回到AbstractAutoProxyCreator里进行正真代理
    * AOP的核心执行都是执行织入的一组 MethodInterceptor ，AopProxy 类会借助下标索引来保证拦截器有序执行
    * 后置处理器中先获取所有增加器,然后筛选出可用的,在加个ExposeInvocationInterceptor 类型的增强器
    * 创建代理工厂,将增加的代理器组合成一个增加器，放入工厂中,AOP的四种声明式通知注解，最终都会转化为对应的 MethodInterceptor ，并且它们都属于通知
    * 然后判断如果目标对象有接口，用jdk动态代理；没有接口，用cglib动态代理。
    * jdk通过Proxy.newProxyInstance实现动态代理
9. JDK目标方法执行JdkDynamicAopProxy
    * jdk动态代理借助接口实现，并且在创建代理对象之前还注入了额外的接口
    * 核心思想都是获取增强器调用链，然后链式执行增强器（拦截器）
    * 执行拦截器链时，为保证拦截器链能有序执行，会引入下标索引机制
10. 事务
    * 执行流程
        - @EnableTransactionManagementz组件@Import最后默认创建AutoProxyRegistrar,ProxyTransactionManagementConfiguration
        - AutoProxyRegistrar在调用beanFactoryPostProcessors时通过后置处理器(postProcessBeanDefinitionRegistry)读取出来
        - AutoProxyRegistrar里面生成创建InfrastructureAdvisorAutoProxyCreator
        - InfrastructureAdvisorAutoProxyCreator得父类也是AbstractAdvisorAutoProxyCreator(AOP得父类),所以实现也一样
        - ProxyTransactionManagementConfiguration注册了多个组件，用来生成事务增强器、事务切入点解析器、事务配置源、事务拦截器等组件  
        - 本质上还是经过动态代理得到JdkDynamicAopProxy,然后invoke,里面通过try{时间执行}catch{回滚}finally{清除缓存}提交
    * 事务传播行为原理，7种类型
        - PROPAGATION_REQUIRED:【默认值：必需】当前方法必须在事务中运行，如果当前线程中没有事务，则开启一个新的事务；  
        如果当前线程中已经存在事务，则方法将会在该事务中运行。
        - PROPAGATION_SUPPORTS:【支持】当前方法单独运行时不需要事务，但如果当前线程中存在事务时，方法会在事务中运行
        - PROPAGATION_MANDATORY:【强制】当前方法必须在事务中运行，如果当前线程中不存在事务，则抛出异常
        - PROPAGATION_REQUIRES_NEW:【新事务】当前方法必须在独立的事务中运行，如果当前线程中已经存在事务，则将该事务挂起，  
        重新开启一个事务，直到方法运行结束再释放之前的事务
        - PROPAGATION_NOT_SUPPORTED:【不支持】当前方法不会在事务中运行，如果当前线程中存在事务，则将事务挂起，直到方法运行结束
        - PROPAGATION_NEVER:【不允许】当前方法不允许在事务中运行，如果当前线程中存在事务，则抛出异常
        - PROPAGATION_NESTED:【嵌套】当前方法必须在事务中运行，如果当前线程中存在事务，则将该事务标注保存点，形成嵌套事务。  
        嵌套事务中的子事务出现异常不会影响到父事务保存点之前的操作。
11. 嵌入式容器Tomcat
    * Tomcat核心容器
        - Service：一个 Tomcat-Server 可以有多个 Service ， Service 中包含下面的所有组件
        - Connector：用于与客户端交互，接收客户端的请求，并将结果响应给客户端
        - Engine：负责处理来自 Service 中的 Connector 的所有请求
        - Host：可理解为主机，一个主机绑定一个端口号
        - Context：可理解为应用，一个主机下有多个应用，一个应用中有多个 Servlet （可以简单理解为 webapps 中一个文件夹代表一个 Context ）
    * onRefresh()中初始化了tomcat,但是因为删除了ServiceConnectors，所以启动时只将所有组件给初始化,并未正在的启动
    * finishRefresh()中归还了Connector,并正在的启动
12. 小问题
    1.  BeanFactory 就是 IOC 容器，FactoryBean 是特殊的 Bean, 用来封装创建比较复杂的对象，而 ObjectFactory 主要用于延迟  
    查找的场景，延迟实例化对象
    2. ApplicationContext继承了BeanFactory，BeanFactory是Spring中比较原始的Factory，它不支持AOP、Web等Spring插件，  
    而ApplicationContext不仅包含了BeanFactory的所有功能，还支持Spring的各种插件，还以一种面向框架的方式工作以及对上下文进行分层和实现继承
    3. ApplicationContext 的主要实现类是ClassPathXmlApplicationContext 和FileSystemXmlApplicationContext，  
    前者默认从类路径加载配置文件，后者默认从文件系统中装载配置文件
13. 设计模式
    * 代理模式：在 AOP 中有使用
    * 单例模式：bean 默认是单例模式
    * 模板方法模式：jdbcTemplate
    * 工厂模式：BeanFactory
    * 观察者模式：Spring 事件驱动模型就是观察者模式很经典的一个应用，比如，ContextStartedEvent 就是 ApplicationContext 启动后触发的事件
    * 适配器模式：Spring MVC 中也是用到了适配器模式适配 Controller
    
    
    
    
    
### Redis
1. 数据结构
    - str,hash,list,set,zset
    - 位图bitmap,位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组
    - HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数,能大概获取UV(今日去重访问人数)
    - Geospatial 可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。
    - Bloom Filter,一般都会在回答缓存穿透，或者海量数据去重这个时候引出来。它实际上是一个很长的二进制向量,然后一个值进来  
    通过多个散列函数映射到二进制向量上令值为1,等查询时再次映射看几个点是否都为1
2. 持久化
    1. RDB,周期性持久化,直接写入数据，适合冷备份。因为是快照文件,默认5分钟一次,期间断电,会丢失数据。虽然同步数据时采用子线程  
    fork操作持久化,但是若数据量特别大生成快照时还是会有秒级别的暂停
    2. AOF,机制对每条写入命令作为日志,适合热备份。占用空间比较大,且比RDB写性能降低
3. 从节点第一次启动连接master时,且为第一次连接master则会触发一个全量复制,slave拿到后立马写进本地磁盘,然后加载到内存,然后master  
    把这段时间内新的操作数据(在内存中的)再发给slave
4. redis过期策略
    1. 定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了.
    2. 惰性删除，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样
    3. 若定期没删,惰性也没去查怎么办?内存淘汰机制
        - 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放
        - 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放
        - 回收随机的键使得新添加的数据有空间存放
        - 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键
        - 报错
5. 底层结构
    * 结构
        - String:动态字符串编码(SDS),优化内存分配的字符串编码,整数编码
        - hash:散列表编码,压缩列表编码
        - list:双向链表编码 ,压缩列表编码 
        - set:散列表编码，整数集合编码
        - zset:跳跃表编码,压缩列表编码
    * 比如当我们的存储只有10个元素的列表，当使用双向链表数据结构时，必然需要维护大量的内部字段如每个元素需要:前置指针，  
    后置指针，数据指针等，造成空间浪费，如果采用连续内存结构的压缩列表(ziplist)，将会节省大量内存，而由于数据长度较小，  
    存取操作时间复杂度即使为O(n2)性能也可满足需求
    * 首先在 Redis 内  部会使用一个 RedisObject 对象来表示所有的 key 和 value,其次 Redis 为了 平衡空间和时间效率，针对 value   
    的具体类型在底层会采用不同的数据结构来实现
    * SDS(Redis 的 SDS 和 C 中字符串相比有什么优势？)
        1. 多增加 len 表示当前字符串的长度：这样就可以直接获取长度了，复杂度 O(1)
        2. 自动扩展空间：当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足修改所需的要求，  
        如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的覆盖情况
        3. 有效降低内存分配次数：C 字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配，SDS 使用了 空间预分配   
        和 惰性空间释放 机制，简单理解就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给 OS   
        4. 二进制安全：C 语言字符串只能保存 ascii 码，对于图片、音频等信息无法保存，SDS 是二进制安全的，写入什么读取  
        就是什么，不做任何过滤和限制
    * 压缩列表:同整数集合一样压缩列表也不是基础数据结构，而是 Redis 自己设计的一种数据存储结构。它有点儿类似数组，通过一片连续的  
    内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同         
6. redis配置 redis.conf
    * maxmemory 内存大小,默认没有配置,默认64位不限制内存大小,32位内存最大为3G 
    * maxmemory 配置的是字节的大小,推荐设置最大物理内存的四分之三
    * config set maxmemory 字节大小 
    * info memory 查看生产内存使用
7. 模型
    * redis使用Reactor模型,由四部分组成,多个套接字,I/O多路复用程序,文件事件分派器，事件处理器.因为文件事件分派器队列的  
    消费是单线程的，所以Redis才叫单线程模型
    * redis通过I/O多路复用程序监听多个套接字,然后将这些请求全部归为一个队列中交给文件事件分配去器中,然后文件事件分配器  
    将队列中的请求一个个取出交给处理器,等处理完成后再拉取下一个请求
8. REDIS集群脑裂以及解决方案?(min-replicas-to-write 3|min-replicas-max-lag 10)第一个参数表示最少的salve节点为3个,  
    第二个参数表示数据复制和同步的延迟不能超过10秒
###  设计模式
1. 分为三大类型(重要原则,对扩展开发，对修改封闭)
    * 创建型模式(这一类设计模式的目的是用于创建对象):抽象工程模式,工厂方法模式,单例模式,构建模式,原型模式
    * 结构型模式(这一类设计模式的目的是优化不同类、对象、接口之间的结构关系)代理模式,装饰者模式,组合模式,桥接模式,适配器模式,  
    外观模式，享元模式
    * 行为模式(这一类设计模式的目的是更好地实现类与类之间的交互以及算法的执行)策略模式,命令模式，状态模式,责任链模式,解释器模式,  
    观察者模式,备忘录模式,迭代器模式,模板方法模式,访问者模式,中介者模式
2. 单例模式
    *. 如果单例初始值是null，还未构建，则构建单例对象并返回。这个写法属于单例模式当中的懒汉模式。如果单例对象一开始就被new Singleton()主动构建，  
    则不再需要判空操作，这种写法属于饿汉模式  
    ``` 
     public class Signleton{
                private Signletion(){};
                private volation static Signleton instance = null;//禁止指令重排序
                public static Signletion getInstance(){
                    if(instance == null){
                        synchroninzed(Signletion.class){
                            if(instance == null){
                                instance = new Signletion();
                            }
                        }
                    }
                }
            }
    ```
    *. 可以使用枚举类来解决反射引起的重复创建对象
3. 策略模式(解决if)
    *. 父类抽象公共方法,子类实现重写,然后上下文类定义type,实例类,比较type方法,使用时静态代码块加载策略到list,循环可以执行所有方法,  
    单独使用比较type,获取到对应实现类
    ``` 
    //定义策略接口
    public interface DealStrategy{
       void dealMythod(String option);
    }
    //定义具体的策略1
    public class DealSina implements DealStrategy{
       @override
       public void dealMythod(String option){
           //...
      }
    }
    //定义具体的策略2
    public class DealWeChat implements DealStrategy{
       @override
       public void dealMythod(String option){
           //...
      }
    }
    //定义上下文，负责使用DealStrategy角色
    public static class DealContext{
       private String type;
       private DealStrategy deal;
       public  DealContext(String type,DealStrategy deal){
           this.type = type;
           this.deal = deal;
       }
       public DealStrategy getDeal(){
           return deal;
       }
       public boolean options(String type){
           return this.type.equals(type);
       }
    }
    
    public void Share{
       private static List<DealContext> algs = new ArrayList();
       //静态代码块,先加载所有的策略
       static {
           algs.add(new DealContext("Sina",new DealSina()));
           algs.add(new DealContext("WeChat",new DealWeChat()));
      }
    public void shareOptions(String type){
           DealStrategy dealStrategy = null;
           for (DealContext deal : algs) {
               if (deal.options(type)) {
                   dealStrategy = deal.getDeal();
                   break;
              }  
          }
           dealStrategy.dealMythod(type);
      }
    }
    ```
4. 观察者模式,是一种基于事件和响应的设计模式
    * 生成观察抽象接口,定义一个更新观察者方法update,定义一个被观察者抽象类,里面包含实现子类列表,然后通知方法。被观察者基础抽象类,  
    观察者实现接口
    ```
     //观察者
     public interface Observer {
         public void update();
     }
     //被观察者
     abstract public class Subject {
         private List<Observer> observerList = new ArrayList<Observer>();
        //。。。。新增删除方法
         public void notifyObservers(){
             for (Observer observer: observerList){
                 observer.update();
             }
         }
     }
     //观察者
     public class Monster implements Observer {
         @Override
         public void update() {
             if(inRange()){
                 System.out.println("怪物 对主角攻击！");
             }
         }
     }
     //被观察者
     public class Hero extends Subject{
         void move(){
             System.out.println("主角向前移动");
             notifyObservers();
         }
     }
     ```
5. 代理模式
    * 静态代理需要为每一个代理对象生成代理类,编译期间实现,动态代理采用反射动态生成代理类,运行期间实现
6. 装饰器模式
    * 生成装饰类,让需要装饰的接口通过构造函数传进来,重写方法,重写方法里面调用接口的方法,加上实现类
    ``` 
    public interface Car {
        void run();
    }
    public class BenzCar implements Car{
        @Override
        public void run() {
            System.out.println("奔驰开车了！");
        }
    }
    public class CarDecorator implements Car {  //继承自Car接口，可以让每一个装饰器本身也可以被更外层的装饰器所包装，
        protected Car decoratedCar;             //包装的方式就是把Car对象作为参数，传入到外层装饰器的构造函数当中。
        public CarDecorator(Car decoratedCar){
            this.decoratedCar = decoratedCar;
        }
        public void run(){
            decoratedCar.run();
        }
    }
    public class AutoCarDecorator extends CarDecorator {
        public AutoCarDecorator(Car decoratedCar){
            super(decoratedCar);
        }
        @Override
        public void run(){
            decoratedCar.run();
            autoRun();
        }
        private void autoRun(){
            System.out.println("开启自动驾驶");
        }}
    ```
    * 装饰模式主要是强调对类中代码的拓展，而代理模式则偏向于委托类的访问限制，换句话 说，用代理模式，代理类（proxy class）  
    可以对它的客户隐藏一个对象的具体信息。因此，当使用代理模式的时候，我们常常在一个代理类中创建一个对象的实例。  
    并且，当我们使用装饰器模 式的时候，我们通常的做法是将原始对象作为一个参数传给装饰者的构造器。
    * 以输入流为例，为了满足不同输入场景，JDK设计了多种多样的输入流，包括ByteArrayInputStream、FileInputStream等等,  
    这些输入流都继承自共同的抽象类：InputStream,与此同时，为了给这些输入流带来功能上的扩展，JDK设计了一个装饰器类，  
    FilterInputStream。该类继承自InputStream，并且“组合”了InputStream成员对象。
7. 外观模式
    * 定义一个大类，里面创建小的功能类,进行运行.想想肯德基的组合套餐
    ``` 
        public class SubSystemA {
            public void methodA(){
                System.out.println("执行方法A");
            }
        }
        public class Facade {
            public void comboMethodA(){
                SubSystemA subSystemA = new SubSystemA();
                SubSystemB subSystemB = new SubSystemB();
                SubSystemD subSystemD = new SubSystemD();
                subSystemA.methodA();
                subSystemB.methodB();
                subSystemD.methodD();
            }
            public void comboMethodB(){
                SubSystemE subSystemE = new SubSystemE();
                SubSystemD subSystemD = new SubSystemD();
                SubSystemB subSystemB = new SubSystemB();
                subSystemE.methodE();
                subSystemD.methodD();
                subSystemB.methodB();
            }
        }
        
        public class Client {
            public static void main(String[] args) {
                Facade facade = new Facade();
                //通过外观模式，调用组合接口A
                facade.comboMethodA();
                //通过外观模式，调用组合接口B
                facade.comboMethodB();
            }
    ```    
8. 责任链模式
    * 面对一个新任务，每个任务处理者需要判断自己能否处理该任务，如果能处理，则处理并返回；如果不能处理，则转交给下一个任务处理者，  
    直到某一个任务处理者最终完成处理。这就是职责链模式的核心思想
    ``` 
    abstract public class Handler {
        protected Handler successor;//每一个Handler对象都包含着一个successor成员，指向它的下一个任务处理者，就像链表节点的next指针一样。
        public void setSuccessor(Handler successor) {
            this.successor = successor;
        }
        abstract String handleRequest(String msg);
    }
    public class HandlerA extends Handler {
        @Override
        String handleRequest(String msg) {
            if(msg.contains("a")){
                msg = msg.replace('a', '*');
            } else if(this.successor != null){
                msg = this.successor.handleRequest(msg); //寻找下一个成员
            }
            return msg;
        }
    }

    ```
    * 当客户端对Web应用发出HTTP请求的时候，会首先经过Tomcat容器的一层层过滤器（Filter），过滤器会针对请求的访问权限、  
    参数合法性等方面进行验证和过滤。这一层一层过滤器的实现，就使用了职责链模式。
    * 在进入Controller层的业务逻辑之前，以及执行完业务逻辑之后，该请求都会经过一系列的拦截器（Interceptor）。  
    这一系列拦截器的处理流程，也同样是职责链模式的实现
9. 工厂模式
    * 分为简单工厂模式,工厂方法模式,抽象工厂模式
        - 简单工厂模式:简单工厂模式有唯一的工厂类，工厂类的创建方法根据传入的参数做if-else条件判断，决定最终创建什么样的产品对象
        - 工厂方法模式:工厂方法模式由多个工厂类实现工厂接口，利用多态来创建不同的产品对象，从而避免了冗长的if-else条件判断
        - 抽象工厂模式把产品子类进行分组，同组中的不同产品由同一个工厂子类的不同方法负责创建，从而减少了工厂子类的数量。
    * 工厂方法模式就是创建工厂模式接口,里面创建工厂方法,不同实现类实现里面创建工厂方法
    ``` 
        public interface IMaskFactory {
            IMask createMask();
        }
        public class HighEndFactory implements IMaskFactory{
            @Override
            public IMask createMask() {
                IMask mask =  new HighEndMask(); //不同子类实现不同创建工厂方法
                return mask;
            }
        }
         
    ```
    
    
### elasticSearch
1. 构成
    1. Cluster:集群，一个ES集群由一个或多个节点（Node）组成，每个集群都有一个cluster name作为标识
    2. node:节点，一个ES实例就是一个node，一个机器可以有多个实例，所以并不能说一台机器就是一个node，  
    大多数情况下每个node运行在一个独立的环境或虚拟机上。
    3. index:索引，即一系列documents的集合
    4. shard:分片，ES是分布式搜索引擎，每个索引有一个或多个分片，索引的数据被分配到各个分片上，相当于一桶水用了N个杯子装，  
    分片有助于横向扩展，N个分片会被尽可能平均地（rebalance）分配在不同的节点上
    5. replica:复制，可以理解为备份分片，相应地有primary shard（主分片），主分片和备分片不会出现在同一个节点上（防止单点故障），  
    默认情况下一个索引创建5个分片5个备份（即5primary+5replica=10个分片）
2. Elasticsearch是如何实现Master选举的?节点之间通过RPC方式发现彼此,对所有可以成为master的节点根据NodeId进行排序,然后投  
    nodeId第一位一票,然后票最多的为master节点,然后解决脑裂问题需要设置最少票数为所有候选节点一半以上
3. ElasticSearch搜索过程
    1. 因为存储时默认根据每条记录的Id字段做路由的,所以Es不知道那个Shard上有需要的结果,所以需要取多个Shard上的数据在分页后  
    返回客户端之前会合并到一个排序后的list列表,所有先query,后fetch
    2. query阶段,会广播到shard中,每个shard在本地执行查询后,生成一个命中文档的list,大小为from+size的总和,这也是为什么Es不要进行  
    深翻页的原因,因为后面from增大,需要查询的数据越多
    3. 然后这个队列只有存有id,然后根据size,取出list优先大小为size的id,发送到对应shard中,然后拉取相应数据,然后返回 
    4. ES为了避免深度分页带来的内存开销，ES默认限定只能查询10000个文档
4. Es更新和删除过程
    1. 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更
    2. 磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。  
    该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段  
    3. 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，  
    新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉
5. Es写入过程  
    1. 默认根据 应当写到那个分片 = hash(_id) % 总共分片树 计算出分配到那个分片,然后调用Lucene的addDocument()方法写入
    2. 当主分片写入成功后，会同时把写入请求发送给所有的副本分片，当副本分片写入成功后，会传回返回信息给主分片，  
    主分片得到所有副本分片的返回信息后，再返回给客户端。
    3. 在shard中，每次写入顺序是先写入Lucene(其实就是创建索引)，再写入TransLog(保证down机数据不会丢失)  
    4. Lucene写入数据后是在内存中,每30分钟或当translog达到一定大小才会flush到磁盘,为了防止down机丢数据,所以引入TransLog
    5. Elasticsearch的主要应用场景就是实时，但Elasticsearch本身并非实时而是近实时,默认1S后才会被查询到，除了GET根据id查询,  
    这种方式是查询TransLog
6. IK分词器,默认有个词的树,以一个个字母或者汉字为单位,每个词就是一个节点,每个节点下面有可通的词,然后能走通代表为一个词,  
    然后句子进来一个个字的走判断词是否可达 
    
    
### springCloud
1. 常用注解
    1. @EnableEurekaServer 开启Eureka服务
    2. @EnableEurekaClient 表明是一个Eureka客户端,@EnableDiscoveryClient(d s 噶 be ru)同样的功能,只不过前者只能是Eureka,后者可以是其他注册中心
    3. @LoadBalanced 开启负载均衡功能(客服端)
    4. @EnableFeignClients 开启Feign的功能     
    5. @FeignClient（"服务名"） 来指定调用哪个服务
    6. @EnableZuulProxy 开启zuul的功能 
    7. @EnableHystrix 开启Hystrix
    8. @HystrixCommand(fallbackMethod ="熔断方法") 指定熔断方法
    9. @EnableConfigServer 开启配置服务器的功能
    10. @RefreshScope 刷新配置文件,实现热部署
2. RestTemplate 是从 Spring3.0 开始支持的一个 HTTP 请求工具，它提供了常见的REST请求方案的模版例如 GET 请求、POST 请求、  
PUT 请求、DELETE 请求以及一些通用的请求执行方法 exchange 以及 execute   
3. Eureka(服务注册于发现。)
    * 特点
        - 当服务注册时,提供元数据,如IP,PORT,URL,主页等等
        - 每隔30s一次心跳校验,90S会删除注册列表中超时服务
        - 心跳校验还会将服务端的注册列表信息缓存至本地,会用该信息查询其他服务,每次心跳更新
        - Eureka Client注册一个实例为什么这么慢?clint默认延迟40s注册,Eureka默认30s更新注册列表
        - zk区别   eureka保证AP,ZK保证CP(C 一致性,A 可用性 P 分区容错性)
        - 每隔10分钟同步一次集群节点,底层通过借助线程池完成定时任务,底层来更新节点信息
    * 源码
        1. @EnableEurekaServer内部@Import(EurekaServerMarkerConfiguration),EurekaServerMarkerConfiguration内部只是简单new了个空的mark
        2. spring.factory SPI加载EurekaServerAutoConfiguration,初始化需要@ConditionalOnBean(EurekaServerMarkerConfiguration.Marker.class)
        3. 所以这个空的mark只是标记,有了它才能执行在SPI加载EurekaServerAutoConfiguration上@Import(EurekaServerInitializerConfiguration.class)
        4. EurekaServerInitializerConfiguration中为核心方法start,其中启动一个新线程,初始化,启动EurekaService,发布Eureka已注册的事件,  
        修改 EurekaServer 的运行状态,发布Eureka已启动的事件
        
4. Fetch(基于动态代理机制，根据注解和选择的机器，拼接请求 url 地址，发起请求)
    - 流程
        1. 通过@EnableFetchClients开启Fetch,根据规则,配置@FetchClient注解
        2. Spring启动流程中会扫描@FetchClient的注解,并将这些类装入IOC容器中
        3. 当请求FetchClient的方法时,会被拦截,拦截类为ReflectiveFetch(r fi de fan qi)
        4. 然后转交到SynchronousMethodHandler类进行拦截的处理,当被拦截会根据参数生成RequestTemplate对象,该对象就是Http的请求模板
        5. RequesTemplate在生成Request
        6. Request交给Client去处理，其中Client可以是HttpUrlConnection、HttpClient也可以是Okhttp
        7. 后Client被封装到LoadBalanceClient类，这个类结合类Ribbon做到了负载均衡。
5. Ribbon(实现负载均衡，从一个服务的多台机器中选择一台)
    - Ribbon的负载均衡，主要通过LoadBalancerClient来实现的
    - LoadBalancerClient具体交给了ILoadBalancer来处理，ILoadBalancer通过配置IRule、IPing等信息，并向EurekaClient获取注册列表的信息
    - 并默认10秒一次向EurekaClient发送“ping”,进而检查是否更新服务列表，最后，得到注册列表后，ILoadBalancer根据IRule的策略进行负载均衡。
    - 而RestTemplate 被@LoadBalance注解后，能过用负载均衡
    - 主要是维护了一个被@LoadBalance注解的RestTemplate列表，并给列表中的RestTemplate添加拦截器，进而交给负载均衡器去处理
6. Hystrix(提供线程池，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题,熔断)
7. Zuul(网关管理，由 Zuul 网关转发请求给对应的服务)
       
